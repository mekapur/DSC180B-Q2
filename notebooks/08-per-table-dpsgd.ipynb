{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Table DP-SGD Synthesis\n",
    "\n",
    "The wide-table DP-SGD approach (notebook 05) failed because extreme sparsity (93-99% zeros in metric columns) caused the VAE to collapse all continuous outputs to near-zero. This notebook takes a different approach: synthesize each reporting table independently, then stitch them together via probabilistic guid assignment.\n",
    "\n",
    "The tradeoff is explicit. Per-table synthesis destroys cross-table correlations (a synthetic guid's chassis type has no relationship to its battery usage pattern), but eliminates the zero-inflation problem because each table is trained only on rows that actually exist.\n",
    "\n",
    "Privacy budget: epsilon=4.0 per table. Under basic composition, the total privacy cost for k tables is k * epsilon. This is standard practice in per-table synthesis; the alternative (splitting a single epsilon across all tables) yields epsilon/k per table, which is too small to be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Device: `cpu`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import display, Markdown\n",
    "from opacus import PrivacyEngine\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "REPORTING_DIR = Path(\"../data/reporting\")\n",
    "SYNTH_DIR = Path(\"../data/reporting/synth_pertable\")\n",
    "RESULTS_REAL = Path(\"../data/results/real\")\n",
    "RESULTS_SYNTH = Path(\"../data/results/synth_pertable\")\n",
    "QUERIES_DIR = Path(\"../docs/queries\")\n",
    "MODELS_DIR = Path(\"../data/models/pertable\")\n",
    "\n",
    "SYNTH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_SYNTH.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_EPSILON = 4.0\n",
    "DELTA = 1e-5\n",
    "MAX_GRAD_NORM = 1.0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "display(Markdown(f\"Device: `{device}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Load all reporting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Loaded 19 reporting tables."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>rows</th>\n",
       "      <th>guids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system_display_devices</td>\n",
       "      <td>220997262</td>\n",
       "      <td>209239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system_mods_top_blocker_hist</td>\n",
       "      <td>92460980</td>\n",
       "      <td>65034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system_frgnd_apps_types</td>\n",
       "      <td>56755998</td>\n",
       "      <td>55830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>system_userwait</td>\n",
       "      <td>34655557</td>\n",
       "      <td>38142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system_web_cat_usage</td>\n",
       "      <td>21354922</td>\n",
       "      <td>64276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system_memory_utilization</td>\n",
       "      <td>11671422</td>\n",
       "      <td>69514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>system_network_consumption</td>\n",
       "      <td>5721356</td>\n",
       "      <td>37224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>system_web_cat_pivot_duration</td>\n",
       "      <td>4537100</td>\n",
       "      <td>64276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>system_on_off_suspend_time_day</td>\n",
       "      <td>1582017</td>\n",
       "      <td>36958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>system_sysinfo_unique_normalized</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>system_cpu_metadata</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>system_os_codename_history</td>\n",
       "      <td>639223</td>\n",
       "      <td>299099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>system_pkg_C0</td>\n",
       "      <td>513353</td>\n",
       "      <td>8943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>system_batt_dc_events</td>\n",
       "      <td>372673</td>\n",
       "      <td>19780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>system_hw_pkg_power</td>\n",
       "      <td>45133</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>system_mods_power_consumption</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>system_pkg_temp_centigrade</td>\n",
       "      <td>2639</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>system_psys_rap_watts</td>\n",
       "      <td>2609</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>system_pkg_avg_freq_mhz</td>\n",
       "      <td>2563</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               table       rows    guids\n",
       "0             system_display_devices  220997262   209239\n",
       "1       system_mods_top_blocker_hist   92460980    65034\n",
       "2            system_frgnd_apps_types   56755998    55830\n",
       "3                    system_userwait   34655557    38142\n",
       "4               system_web_cat_usage   21354922    64276\n",
       "5          system_memory_utilization   11671422    69514\n",
       "6         system_network_consumption    5721356    37224\n",
       "7      system_web_cat_pivot_duration    4537100    64276\n",
       "8     system_on_off_suspend_time_day    1582017    36958\n",
       "9   system_sysinfo_unique_normalized    1000000  1000000\n",
       "10               system_cpu_metadata    1000000  1000000\n",
       "11        system_os_codename_history     639223   299099\n",
       "12                     system_pkg_C0     513353     8943\n",
       "13             system_batt_dc_events     372673    19780\n",
       "14               system_hw_pkg_power      45133      800\n",
       "15     system_mods_power_consumption      10000        1\n",
       "16        system_pkg_temp_centigrade       2639      622\n",
       "17             system_psys_rap_watts       2609      611\n",
       "18           system_pkg_avg_freq_mhz       2563      613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TABLE_NAMES = [\n",
    "    \"system_sysinfo_unique_normalized\",\n",
    "    \"system_cpu_metadata\",\n",
    "    \"system_os_codename_history\",\n",
    "    \"system_network_consumption\",\n",
    "    \"system_memory_utilization\",\n",
    "    \"system_pkg_C0\",\n",
    "    \"system_psys_rap_watts\",\n",
    "    \"system_pkg_avg_freq_mhz\",\n",
    "    \"system_pkg_temp_centigrade\",\n",
    "    \"system_hw_pkg_power\",\n",
    "    \"system_batt_dc_events\",\n",
    "    \"system_web_cat_usage\",\n",
    "    \"system_web_cat_pivot_duration\",\n",
    "    \"system_on_off_suspend_time_day\",\n",
    "    \"system_display_devices\",\n",
    "    \"system_userwait\",\n",
    "    \"system_frgnd_apps_types\",\n",
    "    \"system_mods_top_blocker_hist\",\n",
    "    \"system_mods_power_consumption\",\n",
    "]\n",
    "\n",
    "tables = {}\n",
    "con = duckdb.connect()\n",
    "\n",
    "for name in TABLE_NAMES:\n",
    "    path = REPORTING_DIR / f\"{name}.parquet\"\n",
    "    if path.exists():\n",
    "        nrows = con.execute(f\"SELECT COUNT(*) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        nguids = con.execute(f\"SELECT COUNT(DISTINCT guid) FROM read_parquet('{path}')\").fetchone()[0]\n",
    "        tables[name] = {\"path\": path, \"nrows\": nrows, \"nguids\": nguids}\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"table\": k, \"rows\": v[\"nrows\"], \"guids\": v[\"nguids\"]}\n",
    "    for k, v in tables.items()\n",
    "]).sort_values(\"rows\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(Markdown(f\"Loaded {len(tables)} reporting tables.\"))\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No complete cache found. Will run synthesis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_EXPECTED_PERTABLE = [\n",
    "    \"system_sysinfo_unique_normalized\", \"system_cpu_metadata\",\n",
    "    \"system_os_codename_history\", \"system_network_consumption\",\n",
    "    \"system_memory_utilization\", \"system_batt_dc_events\",\n",
    "    \"system_web_cat_usage\", \"system_web_cat_pivot_duration\",\n",
    "    \"system_on_off_suspend_time_day\", \"system_display_devices\",\n",
    "    \"system_userwait\", \"system_frgnd_apps_types\",\n",
    "    \"system_mods_top_blocker_hist\", \"system_mods_power_consumption\",\n",
    "    \"system_pkg_C0\", \"system_psys_rap_watts\",\n",
    "    \"system_pkg_avg_freq_mhz\", \"system_pkg_temp_centigrade\",\n",
    "    \"system_hw_pkg_power\",\n",
    "]\n",
    "\n",
    "_PERTABLE_CACHED = all((SYNTH_DIR / f\"{t}.parquet\").exists() for t in _EXPECTED_PERTABLE)\n",
    "\n",
    "if _PERTABLE_CACHED:\n",
    "    _PT_CACHE = {t: pd.read_parquet(SYNTH_DIR / f\"{t}.parquet\") for t in _EXPECTED_PERTABLE}\n",
    "    display(Markdown(f\"Found {len(_PT_CACHE)} cached per-table synthetic parquets in `{SYNTH_DIR}`. Skipping synthesis.\"))\n",
    "else:\n",
    "    _PT_CACHE = {}\n",
    "    display(Markdown(\"No complete cache found. Will run synthesis.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Synthesize sysinfo via DP-VAE\n",
    "\n",
    "Sysinfo is the anchor table (1M rows, one per guid). It contains 9 categorical columns and 1 numeric column (ram). A DP-VAE captures the joint distribution of chassis type, country, vendor, OS, CPU, and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sysinfo: 1,000,000 rows, 9 categoricals (top-50), 1 numeric."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chassistype</th>\n",
       "      <th>countryname_normalized</th>\n",
       "      <th>modelvendor_normalized</th>\n",
       "      <th>os</th>\n",
       "      <th>cpuname</th>\n",
       "      <th>cpucode</th>\n",
       "      <th>cpu_family</th>\n",
       "      <th>persona</th>\n",
       "      <th>processornumber</th>\n",
       "      <th>ram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Win10</td>\n",
       "      <td>6th Gen i5</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>Casual User</td>\n",
       "      <td>14 nm</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>India</td>\n",
       "      <td>Gigabyte</td>\n",
       "      <td>Win10</td>\n",
       "      <td>10th Gen i5</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>Casual User</td>\n",
       "      <td>14 nm</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>Korea, Republic of</td>\n",
       "      <td>Asus</td>\n",
       "      <td>Win10</td>\n",
       "      <td>10th Gen i5</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>Casual User</td>\n",
       "      <td>14 nm</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Notebook</td>\n",
       "      <td>Italy</td>\n",
       "      <td>HP</td>\n",
       "      <td>Win10</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Core i7</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>45 nm</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Notebook</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Win10</td>\n",
       "      <td>Pentium/Celeron-Penryn</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Pentium/Celeron</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>45 nm</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chassistype countryname_normalized modelvendor_normalized     os  \\\n",
       "0     Desktop              Australia                Unknown  Win10   \n",
       "1     Desktop                  India               Gigabyte  Win10   \n",
       "2     Desktop     Korea, Republic of                   Asus  Win10   \n",
       "3    Notebook                  Italy                     HP  Win10   \n",
       "4    Notebook                 Brazil                   Dell  Win10   \n",
       "\n",
       "                  cpuname cpucode       cpu_family      persona  \\\n",
       "0              6th Gen i5   OTHER          Core i5  Casual User   \n",
       "1             10th Gen i5   OTHER          Core i5  Casual User   \n",
       "2             10th Gen i5   OTHER          Core i5  Casual User   \n",
       "3                   OTHER   OTHER          Core i7      Unknown   \n",
       "4  Pentium/Celeron-Penryn   OTHER  Pentium/Celeron      Unknown   \n",
       "\n",
       "  processornumber   ram  \n",
       "0           14 nm   8.0  \n",
       "1           14 nm   8.0  \n",
       "2           14 nm  16.0  \n",
       "3           45 nm   6.0  \n",
       "4           45 nm   4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSINFO_CAT_COLS = [\n",
    "    \"chassistype\", \"countryname_normalized\", \"modelvendor_normalized\",\n",
    "    \"os\", \"cpuname\", \"cpucode\", \"cpu_family\", \"persona\", \"processornumber\",\n",
    "]\n",
    "SYSINFO_NUM_COLS = [\"ram\"]\n",
    "SYSINFO_EXTRA_COLS = [\"model_normalized\", \"#ofcores\"]\n",
    "TOP_K = 50\n",
    "\n",
    "sysinfo_path = tables[\"system_sysinfo_unique_normalized\"][\"path\"]\n",
    "sysinfo_df = con.execute(\n",
    "    f\"SELECT guid, {', '.join(SYSINFO_CAT_COLS)}, {', '.join(SYSINFO_NUM_COLS)}, \"\n",
    "    f\"\"\"{', '.join(f'\"{c}\"' if '#' in c else c for c in SYSINFO_EXTRA_COLS)} \"\"\"\n",
    "    f\"FROM read_parquet('{sysinfo_path}')\"\n",
    ").df()\n",
    "\n",
    "for col in SYSINFO_CAT_COLS:\n",
    "    sysinfo_df[col] = sysinfo_df[col].fillna(\"UNKNOWN\").astype(str)\n",
    "    top_vals = sysinfo_df[col].value_counts().head(TOP_K).index.tolist()\n",
    "    sysinfo_df[col] = sysinfo_df[col].where(sysinfo_df[col].isin(top_vals), \"OTHER\")\n",
    "\n",
    "sysinfo_df[\"ram\"] = pd.to_numeric(sysinfo_df[\"ram\"], errors=\"coerce\").fillna(8.0)\n",
    "\n",
    "display(Markdown(f\"Sysinfo: {len(sysinfo_df):,} rows, {len(SYSINFO_CAT_COLS)} categoricals (top-{TOP_K}), {len(SYSINFO_NUM_COLS)} numeric.\"))\n",
    "display(sysinfo_df[SYSINFO_CAT_COLS + SYSINFO_NUM_COLS].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Feature matrix: 1,000,000 x 250 (249 one-hot + 1 numeric)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "cat_encoded = ohe.fit_transform(sysinfo_df[SYSINFO_CAT_COLS])\n",
    "cat_sizes = [len(cats) for cats in ohe.categories_]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_encoded = scaler.fit_transform(sysinfo_df[SYSINFO_NUM_COLS].values)\n",
    "\n",
    "features = np.hstack([cat_encoded, num_encoded]).astype(np.float32)\n",
    "features_tensor = torch.tensor(features)\n",
    "\n",
    "display(Markdown(f\"Feature matrix: {features.shape[0]:,} x {features.shape[1]} ({sum(cat_sizes)} one-hot + {len(SYSINFO_NUM_COLS)} numeric).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "VAE config: input=250, hidden=256, latent=32, 9 categorical heads, 1 numeric outputs.\n",
       "\n",
       "Training: 15 epochs, batch=4096, lr=0.001, \u03b5=4.0, \u03b4=1e-05."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LATENT_DIM = 32\n",
    "HIDDEN_SIZE = 256\n",
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 15\n",
    "LR = 1e-3\n",
    "KL_WEIGHT = 0.1\n",
    "\n",
    "\n",
    "class SysinfoVAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, cat_sizes, num_dim):\n",
    "        super().__init__()\n",
    "        self.cat_sizes = cat_sizes\n",
    "        self.num_dim = num_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, HIDDEN_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mean_layer = nn.Linear(HIDDEN_SIZE // 2, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(HIDDEN_SIZE // 2, latent_dim)\n",
    "\n",
    "        self.cat_decoders = nn.ModuleList(\n",
    "            [nn.Linear(latent_dim, size) for size in cat_sizes]\n",
    "        )\n",
    "        self.num_decoder = nn.Linear(latent_dim, num_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.mean_layer(h), self.logvar_layer(h)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mean + torch.randn_like(std) * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        cat_logits = [dec(z) for dec in self.cat_decoders]\n",
    "        num_out = self.num_decoder(z)\n",
    "        return cat_logits, num_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        cat_logits, num_out = self.decode(z)\n",
    "        return cat_logits, num_out, mean, logvar\n",
    "\n",
    "\n",
    "input_dim = features_tensor.shape[1]\n",
    "num_dim = len(SYSINFO_NUM_COLS)\n",
    "\n",
    "display(Markdown(\n",
    "    f\"VAE config: input={input_dim}, hidden={HIDDEN_SIZE}, latent={LATENT_DIM}, \"\n",
    "    f\"{len(cat_sizes)} categorical heads, {num_dim} numeric outputs.\\n\\n\"\n",
    "    f\"Training: {EPOCHS} epochs, batch={BATCH_SIZE}, lr={LR}, \u03b5={TARGET_EPSILON}, \u03b4={DELTA}.\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Loaded sysinfo VAE from checkpoint. Final \u03b5=4.000, 15 epochs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSINFO_CKPT = MODELS_DIR / \"sysinfo_vae.pt\"\n",
    "\n",
    "dataset = TensorDataset(features_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = SysinfoVAE(input_dim, LATENT_DIM, cat_sizes, num_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "if SYSINFO_CKPT.exists():\n",
    "    ckpt = torch.load(SYSINFO_CKPT, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    sysinfo_epsilon = ckpt[\"final_epsilon\"]\n",
    "    sysinfo_loss_history = ckpt[\"loss_history\"]\n",
    "    display(Markdown(f\"Loaded sysinfo VAE from checkpoint. Final \u03b5={sysinfo_epsilon:.3f}, {len(sysinfo_loss_history)} epochs.\"))\n",
    "    TRAIN_SYSINFO = False\n",
    "else:\n",
    "    TRAIN_SYSINFO = True\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, dataloader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=dataloader,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=TARGET_EPSILON,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=MAX_GRAD_NORM,\n",
    "    )\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    display(Markdown(\n",
    "        f\"Parameters: {total_params:,}. Noise multiplier: {optimizer.noise_multiplier:.4f}.\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SYSINFO:\n",
    "    cat_offsets = [0] + list(np.cumsum(cat_sizes))\n",
    "    sysinfo_loss_history = []\n",
    "    sysinfo_epsilon_history = []\n",
    "    t_start = time.time()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for (batch,) in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cat_logits, num_out, mean, logvar = model(batch)\n",
    "\n",
    "            cat_loss = 0.0\n",
    "            for i, logits in enumerate(cat_logits):\n",
    "                target_onehot = batch[:, cat_offsets[i]:cat_offsets[i+1]]\n",
    "                target_idx = target_onehot.argmax(dim=1)\n",
    "                cat_loss += nn.functional.cross_entropy(logits, target_idx)\n",
    "\n",
    "            num_target = batch[:, cat_offsets[-1]:]\n",
    "            num_loss = nn.functional.mse_loss(num_out, num_target)\n",
    "\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "            loss = cat_loss + num_loss + KL_WEIGHT * kl_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        epoch_loss /= n_batches\n",
    "        sysinfo_loss_history.append(epoch_loss)\n",
    "\n",
    "        try:\n",
    "            eps = privacy_engine.accountant.get_epsilon(delta=DELTA)\n",
    "        except Exception:\n",
    "            eps = float(\"nan\")\n",
    "        sysinfo_epsilon_history.append(eps)\n",
    "\n",
    "        elapsed = time.time() - t_start\n",
    "        per_epoch = elapsed / (epoch + 1)\n",
    "        remaining = per_epoch * (EPOCHS - epoch - 1)\n",
    "\n",
    "        display(Markdown(\n",
    "            f\"Epoch {epoch+1:02d}/{EPOCHS}: loss={epoch_loss:.4f}, \u03b5={eps:.3f} \"\n",
    "            f\"({per_epoch:.0f}s/epoch, ~{remaining/60:.0f}min remaining)\"\n",
    "        ))\n",
    "\n",
    "        if np.isfinite(eps) and eps >= TARGET_EPSILON:\n",
    "            display(Markdown(f\"Target \u03b5={TARGET_EPSILON} reached.\"))\n",
    "            break\n",
    "\n",
    "    sysinfo_epsilon = sysinfo_epsilon_history[-1]\n",
    "    total_min = (time.time() - t_start) / 60\n",
    "    display(Markdown(f\"Training complete in {total_min:.1f} minutes. Final \u03b5={sysinfo_epsilon:.3f}.\"))\n",
    "\n",
    "    torch.save({\n",
    "        \"model_state\": model._module.state_dict() if hasattr(model, \"_module\") else model.state_dict(),\n",
    "        \"final_epsilon\": sysinfo_epsilon,\n",
    "        \"loss_history\": sysinfo_loss_history,\n",
    "        \"cat_sizes\": cat_sizes,\n",
    "        \"input_dim\": input_dim,\n",
    "        \"num_dim\": num_dim,\n",
    "    }, SYSINFO_CKPT)\n",
    "    display(Markdown(f\"Checkpoint saved to `{SYSINFO_CKPT}`.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Generated 1,000,000 synthetic sysinfo rows."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>chassistype</th>\n",
       "      <th>countryname_normalized</th>\n",
       "      <th>modelvendor_normalized</th>\n",
       "      <th>os</th>\n",
       "      <th>cpuname</th>\n",
       "      <th>cpucode</th>\n",
       "      <th>cpu_family</th>\n",
       "      <th>persona</th>\n",
       "      <th>processornumber</th>\n",
       "      <th>ram</th>\n",
       "      <th>model_normalized</th>\n",
       "      <th>#ofcores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synth_0000000</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Win10</td>\n",
       "      <td>6th Gen i5</td>\n",
       "      <td>i5-6300U</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>Casual Gamer</td>\n",
       "      <td>22 nm</td>\n",
       "      <td>8</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synth_0000001</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Win8.1</td>\n",
       "      <td>10th Gen i7</td>\n",
       "      <td>i5-8400</td>\n",
       "      <td>Core i7</td>\n",
       "      <td>Communication</td>\n",
       "      <td>22 nm</td>\n",
       "      <td>12</td>\n",
       "      <td>Other</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synth_0000002</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>HP</td>\n",
       "      <td>Win11</td>\n",
       "      <td>11th Gen i7</td>\n",
       "      <td>i3-8100</td>\n",
       "      <td>Xeon</td>\n",
       "      <td>Content Creator/IT</td>\n",
       "      <td>10 nm</td>\n",
       "      <td>12</td>\n",
       "      <td>HP Pavilion 11 x360 PC</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synth_0000003</td>\n",
       "      <td>Other</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Mouse Computer</td>\n",
       "      <td>Win8.1</td>\n",
       "      <td>3rd Gen i5</td>\n",
       "      <td>i5-6200U</td>\n",
       "      <td>Core2</td>\n",
       "      <td>Office/Productivity</td>\n",
       "      <td>45 nm</td>\n",
       "      <td>12</td>\n",
       "      <td>To be filled by O.E.M.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synth_0000004</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>China</td>\n",
       "      <td>HUAWEI</td>\n",
       "      <td>Win11</td>\n",
       "      <td>8th Gen i7</td>\n",
       "      <td>i7-8750H</td>\n",
       "      <td>Core i7</td>\n",
       "      <td>Office/Productivity</td>\n",
       "      <td>14 nm</td>\n",
       "      <td>8</td>\n",
       "      <td>HKD-WXX</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            guid chassistype countryname_normalized modelvendor_normalized  \\\n",
       "0  synth_0000000     Desktop                  Japan                Unknown   \n",
       "1  synth_0000001     Desktop                 Mexico                Unknown   \n",
       "2  synth_0000002     Desktop              Indonesia                     HP   \n",
       "3  synth_0000003       Other                 Turkey         Mouse Computer   \n",
       "4  synth_0000004    Notebook                  China                 HUAWEI   \n",
       "\n",
       "       os      cpuname   cpucode cpu_family              persona  \\\n",
       "0   Win10   6th Gen i5  i5-6300U    Core i5         Casual Gamer   \n",
       "1  Win8.1  10th Gen i7   i5-8400    Core i7        Communication   \n",
       "2   Win11  11th Gen i7   i3-8100       Xeon   Content Creator/IT   \n",
       "3  Win8.1   3rd Gen i5  i5-6200U      Core2  Office/Productivity   \n",
       "4   Win11   8th Gen i7  i7-8750H    Core i7  Office/Productivity   \n",
       "\n",
       "  processornumber  ram        model_normalized #ofcores  \n",
       "0           22 nm    8                   Other        4  \n",
       "1           22 nm   12                   Other        6  \n",
       "2           10 nm   12  HP Pavilion 11 x360 PC        8  \n",
       "3           45 nm   12  To be filled by O.E.M.        2  \n",
       "4           14 nm    8                 HKD-WXX        4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_SYNTH = 1_000_000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "if _PERTABLE_CACHED:\n",
    "    synth_sysinfo = _PT_CACHE[\"system_sysinfo_unique_normalized\"]\n",
    "    display(Markdown(f\"Loaded cached sysinfo: {len(synth_sysinfo):,} rows.\"))\n",
    "else:\n",
    "    core_model = model._module if hasattr(model, \"_module\") else model\n",
    "    core_model.eval()\n",
    "\n",
    "    synth_rows = []\n",
    "    batch_gen = 10_000\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, N_SYNTH, batch_gen):\n",
    "            n = min(batch_gen, N_SYNTH - start)\n",
    "            z = torch.randn(n, LATENT_DIM, device=device)\n",
    "            cat_logits, num_out = core_model.decode(z)\n",
    "\n",
    "            row_data = {}\n",
    "            for i, (col, logits) in enumerate(zip(SYSINFO_CAT_COLS, cat_logits)):\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                indices = torch.multinomial(probs, 1).squeeze(1).cpu().numpy()\n",
    "                row_data[col] = ohe.categories_[i][indices]\n",
    "\n",
    "            num_vals = scaler.inverse_transform(num_out.cpu().numpy())\n",
    "            row_data[\"ram\"] = np.clip(num_vals[:, 0], 1, 256).round().astype(int)\n",
    "\n",
    "            synth_rows.append(pd.DataFrame(row_data))\n",
    "\n",
    "    synth_sysinfo = pd.concat(synth_rows, ignore_index=True)\n",
    "    synth_sysinfo.insert(0, \"guid\", [f\"synth_{i:07d}\" for i in range(N_SYNTH)])\n",
    "\n",
    "    STANDARD_RAM = np.array([1, 2, 3, 4, 6, 8, 12, 16, 24, 32, 48, 64, 128, 256])\n",
    "    ram_vals = synth_sysinfo[\"ram\"].values.reshape(-1, 1)\n",
    "    nearest_idx = np.abs(ram_vals - STANDARD_RAM.reshape(1, -1)).argmin(axis=1)\n",
    "    synth_sysinfo[\"ram\"] = STANDARD_RAM[nearest_idx]\n",
    "\n",
    "    sysinfo_df[\"model_normalized\"] = sysinfo_df[\"model_normalized\"].fillna(\"Other\").astype(str)\n",
    "    sysinfo_df[\"#ofcores\"] = sysinfo_df[\"#ofcores\"].fillna(\"n/a\").astype(str)\n",
    "\n",
    "    model_by_vendor = sysinfo_df.groupby(\"modelvendor_normalized\")[\"model_normalized\"].apply(list).to_dict()\n",
    "    cores_by_cpu = sysinfo_df.groupby(\"cpuname\")[\"#ofcores\"].apply(list).to_dict()\n",
    "\n",
    "    synth_sysinfo[\"model_normalized\"] = \"Other\"\n",
    "    for vendor, group_idx in synth_sysinfo.groupby(\"modelvendor_normalized\").groups.items():\n",
    "        choices = model_by_vendor.get(vendor, [\"Other\"])\n",
    "        synth_sysinfo.loc[group_idx, \"model_normalized\"] = rng.choice(choices, size=len(group_idx), replace=True)\n",
    "\n",
    "    synth_sysinfo[\"#ofcores\"] = \"n/a\"\n",
    "    for cpu, group_idx in synth_sysinfo.groupby(\"cpuname\").groups.items():\n",
    "        choices = cores_by_cpu.get(cpu, [\"n/a\"])\n",
    "        synth_sysinfo.loc[group_idx, \"#ofcores\"] = rng.choice(choices, size=len(group_idx), replace=True)\n",
    "\n",
    "    display(Markdown(f\"Generated {len(synth_sysinfo):,} synthetic sysinfo rows.\"))\n",
    "    display(synth_sysinfo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sysinfo marginal comparison (top 5 per categorical):"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>value</th>\n",
       "      <th>real_pct</th>\n",
       "      <th>synth_pct</th>\n",
       "      <th>abs_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chassistype</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>58.71</td>\n",
       "      <td>32.95</td>\n",
       "      <td>25.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chassistype</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>33.67</td>\n",
       "      <td>26.84</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chassistype</td>\n",
       "      <td>2 in 1</td>\n",
       "      <td>5.07</td>\n",
       "      <td>16.23</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chassistype</td>\n",
       "      <td>Intel NUC/STK</td>\n",
       "      <td>1.99</td>\n",
       "      <td>8.41</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chassistype</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.97</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>countryname_normalized</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>13.45</td>\n",
       "      <td>7.32</td>\n",
       "      <td>6.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>countryname_normalized</td>\n",
       "      <td>Other</td>\n",
       "      <td>12.54</td>\n",
       "      <td>7.57</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>countryname_normalized</td>\n",
       "      <td>China</td>\n",
       "      <td>5.85</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>countryname_normalized</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>countryname_normalized</td>\n",
       "      <td>India</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>modelvendor_normalized</td>\n",
       "      <td>HP</td>\n",
       "      <td>16.36</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modelvendor_normalized</td>\n",
       "      <td>Dell</td>\n",
       "      <td>13.57</td>\n",
       "      <td>9.28</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>modelvendor_normalized</td>\n",
       "      <td>Lenovo</td>\n",
       "      <td>13.06</td>\n",
       "      <td>8.90</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>modelvendor_normalized</td>\n",
       "      <td>Asus</td>\n",
       "      <td>11.33</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>modelvendor_normalized</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>9.43</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>os</td>\n",
       "      <td>Win10</td>\n",
       "      <td>86.17</td>\n",
       "      <td>38.00</td>\n",
       "      <td>48.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>os</td>\n",
       "      <td>Win11</td>\n",
       "      <td>10.45</td>\n",
       "      <td>21.26</td>\n",
       "      <td>10.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>os</td>\n",
       "      <td>Win8.1</td>\n",
       "      <td>1.49</td>\n",
       "      <td>14.04</td>\n",
       "      <td>12.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>os</td>\n",
       "      <td>Win7</td>\n",
       "      <td>1.46</td>\n",
       "      <td>11.58</td>\n",
       "      <td>10.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>os</td>\n",
       "      <td>Win Server</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cpuname</td>\n",
       "      <td>8th Gen i5</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.84</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cpuname</td>\n",
       "      <td>8th Gen i7</td>\n",
       "      <td>5.97</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cpuname</td>\n",
       "      <td>7th Gen i5</td>\n",
       "      <td>5.57</td>\n",
       "      <td>3.86</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cpuname</td>\n",
       "      <td>4th Gen i5</td>\n",
       "      <td>4.89</td>\n",
       "      <td>3.36</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cpuname</td>\n",
       "      <td>7th Gen i7</td>\n",
       "      <td>4.57</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cpucode</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>54.81</td>\n",
       "      <td>18.84</td>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cpucode</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.92</td>\n",
       "      <td>4.58</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cpucode</td>\n",
       "      <td>i5-7200U</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cpucode</td>\n",
       "      <td>i5-8250U</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cpucode</td>\n",
       "      <td>i7-7700HQ</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>cpu_family</td>\n",
       "      <td>Core i5</td>\n",
       "      <td>38.11</td>\n",
       "      <td>23.00</td>\n",
       "      <td>15.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cpu_family</td>\n",
       "      <td>Core i7</td>\n",
       "      <td>28.43</td>\n",
       "      <td>21.12</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cpu_family</td>\n",
       "      <td>Core i3</td>\n",
       "      <td>14.71</td>\n",
       "      <td>15.89</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>cpu_family</td>\n",
       "      <td>Pentium/Celeron</td>\n",
       "      <td>11.05</td>\n",
       "      <td>11.35</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>cpu_family</td>\n",
       "      <td>Other</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.01</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>persona</td>\n",
       "      <td>Web User</td>\n",
       "      <td>25.29</td>\n",
       "      <td>15.64</td>\n",
       "      <td>9.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>persona</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22.15</td>\n",
       "      <td>14.84</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>persona</td>\n",
       "      <td>Casual User</td>\n",
       "      <td>12.14</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>persona</td>\n",
       "      <td>Gamer</td>\n",
       "      <td>9.32</td>\n",
       "      <td>10.55</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>persona</td>\n",
       "      <td>Casual Gamer</td>\n",
       "      <td>7.04</td>\n",
       "      <td>9.52</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>processornumber</td>\n",
       "      <td>14 nm</td>\n",
       "      <td>56.23</td>\n",
       "      <td>26.80</td>\n",
       "      <td>29.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>processornumber</td>\n",
       "      <td>22 nm</td>\n",
       "      <td>21.47</td>\n",
       "      <td>17.13</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>processornumber</td>\n",
       "      <td>32 nm</td>\n",
       "      <td>9.20</td>\n",
       "      <td>11.18</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>processornumber</td>\n",
       "      <td>10 nm</td>\n",
       "      <td>4.70</td>\n",
       "      <td>9.77</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>processornumber</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column                     value  real_pct  synth_pct  \\\n",
       "0              chassistype                  Notebook     58.71      32.95   \n",
       "1              chassistype                   Desktop     33.67      26.84   \n",
       "2              chassistype                    2 in 1      5.07      16.23   \n",
       "3              chassistype             Intel NUC/STK      1.99       8.41   \n",
       "4              chassistype                     Other      0.36       6.97   \n",
       "5   countryname_normalized  United States of America     13.45       7.32   \n",
       "6   countryname_normalized                     Other     12.54       7.57   \n",
       "7   countryname_normalized                     China      5.85       4.90   \n",
       "8   countryname_normalized                    Brazil      5.32       4.84   \n",
       "9   countryname_normalized                     India      4.86       4.77   \n",
       "10  modelvendor_normalized                        HP     16.36       9.85   \n",
       "11  modelvendor_normalized                      Dell     13.57       9.28   \n",
       "12  modelvendor_normalized                    Lenovo     13.06       8.90   \n",
       "13  modelvendor_normalized                      Asus     11.33       9.81   \n",
       "14  modelvendor_normalized                   Unknown      9.43       6.88   \n",
       "15                      os                     Win10     86.17      38.00   \n",
       "16                      os                     Win11     10.45      21.26   \n",
       "17                      os                    Win8.1      1.49      14.04   \n",
       "18                      os                      Win7      1.46      11.58   \n",
       "19                      os                Win Server      0.31       5.77   \n",
       "20                 cpuname                8th Gen i5      6.88       4.84   \n",
       "21                 cpuname                8th Gen i7      5.97       5.73   \n",
       "22                 cpuname                7th Gen i5      5.57       3.86   \n",
       "23                 cpuname                4th Gen i5      4.89       3.36   \n",
       "24                 cpuname                7th Gen i7      4.57       3.97   \n",
       "25                 cpucode                     OTHER     54.81      18.84   \n",
       "26                 cpucode                   Unknown      2.92       4.58   \n",
       "27                 cpucode                  i5-7200U      2.74       3.94   \n",
       "28                 cpucode                  i5-8250U      2.59       2.22   \n",
       "29                 cpucode                 i7-7700HQ      1.88       2.28   \n",
       "30              cpu_family                   Core i5     38.11      23.00   \n",
       "31              cpu_family                   Core i7     28.43      21.12   \n",
       "32              cpu_family                   Core i3     14.71      15.89   \n",
       "33              cpu_family           Pentium/Celeron     11.05      11.35   \n",
       "34              cpu_family                     Other      2.88       8.01   \n",
       "35                 persona                  Web User     25.29      15.64   \n",
       "36                 persona                   Unknown     22.15      14.84   \n",
       "37                 persona               Casual User     12.14      11.75   \n",
       "38                 persona                     Gamer      9.32      10.55   \n",
       "39                 persona              Casual Gamer      7.04       9.52   \n",
       "40         processornumber                     14 nm     56.23      26.80   \n",
       "41         processornumber                     22 nm     21.47      17.13   \n",
       "42         processornumber                     32 nm      9.20      11.18   \n",
       "43         processornumber                     10 nm      4.70       9.77   \n",
       "44         processornumber                   Unknown      2.88       8.62   \n",
       "\n",
       "    abs_diff  \n",
       "0      25.75  \n",
       "1       6.83  \n",
       "2      11.16  \n",
       "3       6.41  \n",
       "4       6.61  \n",
       "5       6.13  \n",
       "6       4.97  \n",
       "7       0.95  \n",
       "8       0.48  \n",
       "9       0.09  \n",
       "10      6.51  \n",
       "11      4.28  \n",
       "12      4.16  \n",
       "13      1.52  \n",
       "14      2.54  \n",
       "15     48.16  \n",
       "16     10.82  \n",
       "17     12.55  \n",
       "18     10.12  \n",
       "19      5.46  \n",
       "20      2.04  \n",
       "21      0.23  \n",
       "22      1.71  \n",
       "23      1.53  \n",
       "24      0.60  \n",
       "25     35.98  \n",
       "26      1.66  \n",
       "27      1.19  \n",
       "28      0.37  \n",
       "29      0.40  \n",
       "30     15.11  \n",
       "31      7.31  \n",
       "32      1.18  \n",
       "33      0.29  \n",
       "34      5.13  \n",
       "35      9.64  \n",
       "36      7.31  \n",
       "37      0.40  \n",
       "38      1.24  \n",
       "39      2.48  \n",
       "40     29.43  \n",
       "41      4.34  \n",
       "42      1.98  \n",
       "43      5.07  \n",
       "44      5.74  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"Sysinfo marginal comparison (top 5 per categorical):\"))\n",
    "\n",
    "comparison_rows = []\n",
    "for col in SYSINFO_CAT_COLS:\n",
    "    real_dist = sysinfo_df[col].value_counts(normalize=True).head(5)\n",
    "    synth_dist = synth_sysinfo[col].value_counts(normalize=True)\n",
    "    for val in real_dist.index:\n",
    "        r = real_dist[val]\n",
    "        s = synth_dist.get(val, 0.0)\n",
    "        comparison_rows.append({\n",
    "            \"column\": col, \"value\": val,\n",
    "            \"real_pct\": round(r * 100, 2), \"synth_pct\": round(s * 100, 2),\n",
    "            \"abs_diff\": round(abs(r - s) * 100, 2),\n",
    "        })\n",
    "\n",
    "display(pd.DataFrame(comparison_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Synthesize cpu_metadata via DP-VAE\n",
    "\n",
    "cpu_metadata is a 1M-row categorical table (one row per guid) with columns like cpucode, marketcodename, cpugen, processtechnology, #ofcores, spec_tdp. Same VAE approach as sysinfo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "cpu_metadata: 1,000,000 rows, feature dim=186."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CPU_CAT_COLS = [\"cpucode\", \"processtechnology\", \"marketcodename\", \"cpugen\", \"#ofcores\"]\n",
    "CPU_NUM_COLS = [\"spec_tdp\"]\n",
    "\n",
    "cpu_path = tables[\"system_cpu_metadata\"][\"path\"]\n",
    "cpu_df = con.execute(\n",
    "    f\"\"\"SELECT guid, cpucode, processtechnology, marketcodename, cpugen, \n",
    "    \\\"#ofcores\\\", spec_tdp FROM read_parquet('{cpu_path}')\"\"\"\n",
    ").df()\n",
    "\n",
    "for col in CPU_CAT_COLS:\n",
    "    cpu_df[col] = cpu_df[col].fillna(\"Unknown\").astype(str)\n",
    "    top_vals = cpu_df[col].value_counts().head(TOP_K).index.tolist()\n",
    "    cpu_df[col] = cpu_df[col].where(cpu_df[col].isin(top_vals), \"Other\")\n",
    "\n",
    "cpu_df[\"spec_tdp\"] = pd.to_numeric(cpu_df[\"spec_tdp\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "cpu_ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "cpu_cat_enc = cpu_ohe.fit_transform(cpu_df[CPU_CAT_COLS])\n",
    "cpu_cat_sizes = [len(c) for c in cpu_ohe.categories_]\n",
    "\n",
    "cpu_scaler = StandardScaler()\n",
    "cpu_num_enc = cpu_scaler.fit_transform(cpu_df[CPU_NUM_COLS].values)\n",
    "\n",
    "cpu_features = np.hstack([cpu_cat_enc, cpu_num_enc]).astype(np.float32)\n",
    "cpu_tensor = torch.tensor(cpu_features)\n",
    "\n",
    "display(Markdown(f\"cpu_metadata: {len(cpu_df):,} rows, feature dim={cpu_features.shape[1]}.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Noise multiplier: 0.6628."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CPU_CKPT = MODELS_DIR / \"cpu_metadata_vae.pt\"\n",
    "\n",
    "cpu_dataset = TensorDataset(cpu_tensor)\n",
    "cpu_loader = DataLoader(cpu_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "cpu_model = SysinfoVAE(cpu_features.shape[1], LATENT_DIM, cpu_cat_sizes, len(CPU_NUM_COLS)).to(device)\n",
    "cpu_optimizer = torch.optim.Adam(cpu_model.parameters(), lr=LR)\n",
    "\n",
    "if CPU_CKPT.exists():\n",
    "    ckpt = torch.load(CPU_CKPT, map_location=device, weights_only=False)\n",
    "    cpu_model.load_state_dict(ckpt[\"model_state\"])\n",
    "    display(Markdown(f\"Loaded cpu_metadata VAE from checkpoint. \u03b5={ckpt['final_epsilon']:.3f}.\"))\n",
    "    TRAIN_CPU = False\n",
    "else:\n",
    "    TRAIN_CPU = True\n",
    "    cpu_pe = PrivacyEngine()\n",
    "    cpu_model, cpu_optimizer, cpu_loader = cpu_pe.make_private_with_epsilon(\n",
    "        module=cpu_model, optimizer=cpu_optimizer, data_loader=cpu_loader,\n",
    "        epochs=EPOCHS, target_epsilon=TARGET_EPSILON, target_delta=DELTA,\n",
    "        max_grad_norm=MAX_GRAD_NORM,\n",
    "    )\n",
    "    display(Markdown(f\"Noise multiplier: {cpu_optimizer.noise_multiplier:.4f}.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Epoch 01/15: loss=7.6361, \u03b5=1.898 (73s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 02/15: loss=1.1247, \u03b5=2.201 (87s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 03/15: loss=0.4601, \u03b5=2.419 (87s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 04/15: loss=0.3227, \u03b5=2.603 (88s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 05/15: loss=0.2588, \u03b5=2.766 (91s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 06/15: loss=0.2197, \u03b5=2.917 (93s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 07/15: loss=0.1974, \u03b5=3.057 (92s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 08/15: loss=0.1811, \u03b5=3.191 (91s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Epoch 09/15: loss=0.1694, \u03b5=3.318 (91s/epoch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN_CPU:\n",
    "    cpu_cat_offsets = [0] + list(np.cumsum(cpu_cat_sizes))\n",
    "    cpu_loss_hist = []\n",
    "    t_start = time.time()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        cpu_model.train()\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for (batch,) in cpu_loader:\n",
    "            batch = batch.to(device)\n",
    "            cpu_optimizer.zero_grad()\n",
    "            cat_logits, num_out, mean, logvar = cpu_model(batch)\n",
    "\n",
    "            cat_loss = sum(\n",
    "                nn.functional.cross_entropy(logits, batch[:, cpu_cat_offsets[i]:cpu_cat_offsets[i+1]].argmax(dim=1))\n",
    "                for i, logits in enumerate(cat_logits)\n",
    "            )\n",
    "            num_loss = nn.functional.mse_loss(num_out, batch[:, cpu_cat_offsets[-1]:])\n",
    "            kl_loss = -0.5 * torch.mean(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "            loss = cat_loss + num_loss + KL_WEIGHT * kl_loss\n",
    "            loss.backward()\n",
    "            cpu_optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        epoch_loss /= n_batches\n",
    "        cpu_loss_hist.append(epoch_loss)\n",
    "\n",
    "        try:\n",
    "            eps = cpu_pe.accountant.get_epsilon(delta=DELTA)\n",
    "        except Exception:\n",
    "            eps = float(\"nan\")\n",
    "\n",
    "        elapsed = time.time() - t_start\n",
    "        display(Markdown(f\"Epoch {epoch+1:02d}/{EPOCHS}: loss={epoch_loss:.4f}, \u03b5={eps:.3f} ({elapsed/(epoch+1):.0f}s/epoch)\"))\n",
    "\n",
    "        if np.isfinite(eps) and eps >= TARGET_EPSILON:\n",
    "            display(Markdown(f\"Target \u03b5 reached.\"))\n",
    "            break\n",
    "\n",
    "    cpu_core = cpu_model._module if hasattr(cpu_model, \"_module\") else cpu_model\n",
    "    torch.save({\n",
    "        \"model_state\": cpu_core.state_dict(),\n",
    "        \"final_epsilon\": eps,\n",
    "        \"loss_history\": cpu_loss_hist,\n",
    "    }, CPU_CKPT)\n",
    "    display(Markdown(f\"cpu_metadata VAE saved. Final \u03b5={eps:.3f}.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_cpu = _PT_CACHE[\"system_cpu_metadata\"]\n",
    "    display(Markdown(f\"Loaded cached cpu_metadata: {len(synth_cpu):,} rows.\"))\n",
    "else:\n",
    "    cpu_core = cpu_model._module if hasattr(cpu_model, \"_module\") else cpu_model\n",
    "    cpu_core.eval()\n",
    "\n",
    "    cpu_synth_rows = []\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, N_SYNTH, 10_000):\n",
    "            n = min(10_000, N_SYNTH - start)\n",
    "            z = torch.randn(n, LATENT_DIM, device=device)\n",
    "            cat_logits, num_out = cpu_core.decode(z)\n",
    "\n",
    "            row_data = {}\n",
    "            for i, (col, logits) in enumerate(zip(CPU_CAT_COLS, cat_logits)):\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                indices = torch.multinomial(probs, 1).squeeze(1).cpu().numpy()\n",
    "                row_data[col] = cpu_ohe.categories_[i][indices]\n",
    "\n",
    "            num_vals = cpu_scaler.inverse_transform(num_out.cpu().numpy())\n",
    "            row_data[\"spec_tdp\"] = np.clip(num_vals[:, 0], 0, 300).round(1)\n",
    "\n",
    "            cpu_synth_rows.append(pd.DataFrame(row_data))\n",
    "\n",
    "    synth_cpu = pd.concat(cpu_synth_rows, ignore_index=True)\n",
    "    synth_cpu.insert(0, \"guid\", synth_sysinfo[\"guid\"].values)\n",
    "\n",
    "    display(Markdown(f\"Generated {len(synth_cpu):,} synthetic cpu_metadata rows.\"))\n",
    "    display(synth_cpu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Synthesize os_codename_history via DP histogram\n",
    "\n",
    "os_codename_history has 639K rows with (guid, os_name, os_codename, min_ts, max_ts). Queries use this to filter blocker data by OS version. Synthesize os_name x os_codename as a joint categorical distribution with Laplace noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_os = _PT_CACHE[\"system_os_codename_history\"]\n",
    "    display(Markdown(f\"Loaded cached os_codename_history: {len(synth_os):,} rows.\"))\n",
    "else:\n",
    "    os_path = tables[\"system_os_codename_history\"][\"path\"]\n",
    "    os_df = con.execute(\n",
    "        f\"SELECT guid, os_name, os_codename, min_ts, max_ts FROM read_parquet('{os_path}')\"\n",
    "    ).df()\n",
    "\n",
    "    os_df[\"os_name\"] = os_df[\"os_name\"].fillna(\"Unknown\").astype(str)\n",
    "    os_df[\"os_codename\"] = os_df[\"os_codename\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "    os_joint = os_df.groupby([\"os_name\", \"os_codename\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    sensitivity = 1\n",
    "    noise_scale = sensitivity / TARGET_EPSILON\n",
    "    os_joint[\"noisy_count\"] = os_joint[\"count\"] + np.random.laplace(0, noise_scale, len(os_joint))\n",
    "    os_joint[\"noisy_count\"] = os_joint[\"noisy_count\"].clip(lower=0)\n",
    "    os_joint[\"prob\"] = os_joint[\"noisy_count\"] / os_joint[\"noisy_count\"].sum()\n",
    "\n",
    "    real_guid_count = os_df[\"guid\"].nunique()\n",
    "    real_join_rate = real_guid_count / tables[\"system_sysinfo_unique_normalized\"][\"nguids\"]\n",
    "    synth_os_n = int(N_SYNTH * real_join_rate)\n",
    "\n",
    "    sampled_indices = rng.choice(len(os_joint), size=synth_os_n, p=os_joint[\"prob\"].values)\n",
    "    synth_os = os_joint.iloc[sampled_indices][[\"os_name\", \"os_codename\"]].reset_index(drop=True)\n",
    "\n",
    "    assigned_guids = rng.choice(synth_sysinfo[\"guid\"].values, size=synth_os_n, replace=False)\n",
    "    synth_os.insert(0, \"guid\", assigned_guids)\n",
    "\n",
    "    real_ts_range = os_df[[\"min_ts\", \"max_ts\"]].describe().loc[[\"min\", \"max\"]]\n",
    "    synth_os[\"min_ts\"] = os_df[\"min_ts\"].sample(synth_os_n, replace=True).values\n",
    "    synth_os[\"max_ts\"] = os_df[\"max_ts\"].sample(synth_os_n, replace=True).values\n",
    "\n",
    "    display(Markdown(f\"os_codename_history: {real_guid_count:,} real guids ({real_join_rate:.1%} join rate) \u2192 {synth_os_n:,} synthetic rows.\"))\n",
    "    display(synth_os.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Synthesize metric tables via discretized DP histograms\n",
    "\n",
    "For tables with numeric data (network, memory, pkg_C0, psys_rap, freq, temp, hw_pkg_power, battery, on_off, web_cat_pivot), the approach is:\n",
    "\n",
    "1. Aggregate to guid level (weighted averages, sums).\n",
    "2. For each numeric column, discretize into bins.\n",
    "3. Count joint histogram of all discretized columns.\n",
    "4. Add Laplace noise (sensitivity=1 per guid contributing to one bin).\n",
    "5. Sample from the noisy distribution.\n",
    "\n",
    "Joint histograms over many columns are infeasible (curse of dimensionality). Instead, we use independent marginal histograms per column and sample each column independently. This loses within-table correlations but keeps per-column distributions accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_histogram_synthesis(df, guid_col, num_cols, cat_cols, n_synth, epsilon, n_bins=20, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(42)\n",
    "\n",
    "    eps_per_col = epsilon / (len(num_cols) + len(cat_cols))\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    bin_edges = {}\n",
    "    for col in num_cols:\n",
    "        vals = pd.to_numeric(df[col], errors=\"coerce\").dropna().values\n",
    "        if len(vals) == 0:\n",
    "            continue\n",
    "        lo, hi = np.percentile(vals, [1, 99])\n",
    "        if lo == hi:\n",
    "            hi = lo + 1\n",
    "        edges = np.linspace(lo, hi, n_bins + 1)\n",
    "        bin_edges[col] = edges\n",
    "\n",
    "        counts, _ = np.histogram(vals, bins=edges)\n",
    "        noise = np.random.laplace(0, 1.0 / eps_per_col, len(counts))\n",
    "        noisy_counts = np.clip(counts + noise, 0, None)\n",
    "        total = noisy_counts.sum()\n",
    "        if total == 0:\n",
    "            probs = np.ones(len(noisy_counts)) / len(noisy_counts)\n",
    "        else:\n",
    "            probs = noisy_counts / total\n",
    "\n",
    "        bin_indices = rng.choice(len(probs), size=n_synth, p=probs)\n",
    "        midpoints = (edges[:-1] + edges[1:]) / 2\n",
    "        bin_width = edges[1] - edges[0]\n",
    "        result[col] = midpoints[bin_indices] + rng.uniform(-bin_width/2, bin_width/2, n_synth)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        vc = df[col].fillna(\"Unknown\").astype(str).value_counts()\n",
    "        counts = vc.values.astype(float)\n",
    "        noise = np.random.laplace(0, 1.0 / eps_per_col, len(counts))\n",
    "        noisy_counts = np.clip(counts + noise, 0, None)\n",
    "        total = noisy_counts.sum()\n",
    "        if total == 0:\n",
    "            probs = np.ones(len(noisy_counts)) / len(noisy_counts)\n",
    "        else:\n",
    "            probs = noisy_counts / total\n",
    "        result[col] = rng.choice(vc.index.values, size=n_synth, p=probs)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_join_rate(table_name):\n",
    "    return tables[table_name][\"nguids\"] / tables[\"system_sysinfo_unique_normalized\"][\"nguids\"]\n",
    "\n",
    "\n",
    "def assign_guids(n_synth, rng):\n",
    "    return rng.choice(synth_sysinfo[\"guid\"].values, size=min(n_synth, N_SYNTH), replace=False)\n",
    "\n",
    "\n",
    "def synth_table_info(name, synth_df, join_rate):\n",
    "    display(Markdown(f\"{name}: join rate={join_rate:.3%}, {len(synth_df):,} synthetic rows.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_network = _PT_CACHE[\"system_network_consumption\"]\n",
    "    display(Markdown(f\"Loaded cached network_consumption: {len(synth_network):,} rows.\"))\n",
    "else:\n",
    "    net_path = tables[\"system_network_consumption\"][\"path\"]\n",
    "    net_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, input_desc,\n",
    "            SUM(nrs) as nrs,\n",
    "            SUM(nrs * avg_bytes_sec) / SUM(nrs) as avg_bytes_sec\n",
    "        FROM read_parquet('{net_path}')\n",
    "        GROUP BY guid, input_desc\n",
    "    \"\"\").df()\n",
    "\n",
    "    net_received = net_agg[net_agg[\"input_desc\"].str.contains(\"RECEIVED\")].rename(\n",
    "        columns={\"nrs\": \"recv_nrs\", \"avg_bytes_sec\": \"recv_avg\"}\n",
    "    )[[\"guid\", \"recv_nrs\", \"recv_avg\"]]\n",
    "    net_sent = net_agg[net_agg[\"input_desc\"].str.contains(\"SENT\")].rename(\n",
    "        columns={\"nrs\": \"sent_nrs\", \"avg_bytes_sec\": \"sent_avg\"}\n",
    "    )[[\"guid\", \"sent_nrs\", \"sent_avg\"]]\n",
    "\n",
    "    net_guid = net_received.merge(net_sent, on=\"guid\", how=\"outer\").fillna(0)\n",
    "\n",
    "    join_rate = compute_join_rate(\"system_network_consumption\")\n",
    "    n_net = int(N_SYNTH * join_rate)\n",
    "\n",
    "    synth_net_wide = dp_histogram_synthesis(\n",
    "        net_guid, \"guid\",\n",
    "        num_cols=[\"recv_nrs\", \"recv_avg\", \"sent_nrs\", \"sent_avg\"],\n",
    "        cat_cols=[],\n",
    "        n_synth=n_net, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "\n",
    "    synth_net_wide[\"recv_nrs\"] = synth_net_wide[\"recv_nrs\"].clip(lower=1).round()\n",
    "    synth_net_wide[\"sent_nrs\"] = synth_net_wide[\"sent_nrs\"].clip(lower=1).round()\n",
    "    synth_net_wide[\"recv_avg\"] = synth_net_wide[\"recv_avg\"].clip(lower=0)\n",
    "    synth_net_wide[\"sent_avg\"] = synth_net_wide[\"sent_avg\"].clip(lower=0)\n",
    "\n",
    "    guids = assign_guids(n_net, rng)\n",
    "    received_rows = pd.DataFrame({\n",
    "        \"guid\": guids,\n",
    "        \"input_desc\": \"OS:NETWORK INTERFACE::BYTES RECEIVED/SEC::\",\n",
    "        \"nrs\": synth_net_wide[\"recv_nrs\"].values,\n",
    "        \"avg_bytes_sec\": synth_net_wide[\"recv_avg\"].values,\n",
    "    })\n",
    "    sent_rows = pd.DataFrame({\n",
    "        \"guid\": guids,\n",
    "        \"input_desc\": \"OS:NETWORK INTERFACE::BYTES SENT/SEC::\",\n",
    "        \"nrs\": synth_net_wide[\"sent_nrs\"].values,\n",
    "        \"avg_bytes_sec\": synth_net_wide[\"sent_avg\"].values,\n",
    "    })\n",
    "    synth_network = pd.concat([received_rows, sent_rows], ignore_index=True)\n",
    "\n",
    "    synth_table_info(\"network_consumption\", synth_network, join_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_memory = _PT_CACHE[\"system_memory_utilization\"]\n",
    "    display(Markdown(f\"Loaded cached memory_utilization: {len(synth_memory):,} rows.\"))\n",
    "else:\n",
    "    mem_path = tables[\"system_memory_utilization\"][\"path\"]\n",
    "    mem_agg = con.execute(f\"\"\"\n",
    "        SELECT guid,\n",
    "            SUM(nrs) as nrs,\n",
    "            SUM(nrs * avg_percentage_used) / SUM(nrs) as avg_percentage_used,\n",
    "            MAX(sysinfo_ram) as sysinfo_ram\n",
    "        FROM read_parquet('{mem_path}')\n",
    "        WHERE avg_percentage_used > 0\n",
    "        GROUP BY guid\n",
    "    \"\"\").df()\n",
    "\n",
    "    join_rate = compute_join_rate(\"system_memory_utilization\")\n",
    "    n_mem = int(N_SYNTH * join_rate)\n",
    "\n",
    "    synth_mem_wide = dp_histogram_synthesis(\n",
    "        mem_agg, \"guid\",\n",
    "        num_cols=[\"nrs\", \"avg_percentage_used\", \"sysinfo_ram\"],\n",
    "        cat_cols=[],\n",
    "        n_synth=n_mem, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "\n",
    "    synth_mem_wide[\"nrs\"] = synth_mem_wide[\"nrs\"].clip(lower=1).round()\n",
    "    synth_mem_wide[\"avg_percentage_used\"] = synth_mem_wide[\"avg_percentage_used\"].clip(0, 100).round()\n",
    "    synth_mem_wide[\"sysinfo_ram\"] = (synth_mem_wide[\"sysinfo_ram\"].clip(lower=1024) / 1024).round() * 1024\n",
    "\n",
    "    synth_memory = synth_mem_wide.copy()\n",
    "    synth_memory.insert(0, \"guid\", assign_guids(n_mem, rng))\n",
    "\n",
    "    synth_table_info(\"memory_utilization\", synth_memory, join_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware metric tables (pkg_C0, psys_rap, freq, temp, pkg_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_tables_config = {\n",
    "    \"system_pkg_C0\": {\"avg_col\": \"avg_pkg_c0\", \"min_col\": \"min_pkg_c0\", \"max_col\": \"max_pkg_c0\"},\n",
    "    \"system_psys_rap_watts\": {\"avg_col\": \"avg_psys_rap_watts\", \"min_col\": \"min_psys_rap_watts\", \"max_col\": \"max_psys_rap_watts\"},\n",
    "    \"system_pkg_avg_freq_mhz\": {\"avg_col\": \"avg_avg_freq_mhz\", \"min_col\": \"min_avg_freq_mhz\", \"max_col\": \"max_avg_freq_mhz\"},\n",
    "    \"system_pkg_temp_centigrade\": {\"avg_col\": \"avg_temp_centigrade\", \"min_col\": \"min_temp_centigrade\", \"max_col\": \"max_temp_centigrade\"},\n",
    "}\n",
    "\n",
    "if _PERTABLE_CACHED:\n",
    "    synth_hw = {tname: _PT_CACHE[tname] for tname in hw_tables_config}\n",
    "    display(Markdown(f\"Loaded {len(synth_hw)} cached hw metric tables.\"))\n",
    "else:\n",
    "    synth_hw = {}\n",
    "\n",
    "    for tname, cols in hw_tables_config.items():\n",
    "        tpath = tables[tname][\"path\"]\n",
    "        agg = con.execute(f\"\"\"\n",
    "            SELECT guid,\n",
    "                SUM(nrs) as nrs,\n",
    "                SUM(nrs * \\\"{cols['avg_col']}\\\") / SUM(nrs) as {cols['avg_col']}\n",
    "            FROM read_parquet('{tpath}')\n",
    "            GROUP BY guid\n",
    "        \"\"\").df()\n",
    "\n",
    "        jr = compute_join_rate(tname)\n",
    "        n = max(int(N_SYNTH * jr), 10)\n",
    "\n",
    "        synth_wide = dp_histogram_synthesis(\n",
    "            agg, \"guid\",\n",
    "            num_cols=[\"nrs\", cols[\"avg_col\"]],\n",
    "            cat_cols=[],\n",
    "            n_synth=n, epsilon=TARGET_EPSILON, rng=rng,\n",
    "        )\n",
    "        synth_wide[\"nrs\"] = synth_wide[\"nrs\"].clip(lower=1).round()\n",
    "        synth_wide[cols[\"avg_col\"]] = synth_wide[cols[\"avg_col\"]].clip(lower=0)\n",
    "        synth_wide.insert(0, \"guid\", assign_guids(n, rng)[:n])\n",
    "\n",
    "        synth_hw[tname] = synth_wide\n",
    "        synth_table_info(tname, synth_wide, jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_hw[\"system_hw_pkg_power\"] = _PT_CACHE[\"system_hw_pkg_power\"]\n",
    "    display(Markdown(f\"Loaded cached hw_pkg_power: {len(synth_hw['system_hw_pkg_power']):,} rows.\"))\n",
    "else:\n",
    "    pkg_path = tables[\"system_hw_pkg_power\"][\"path\"]\n",
    "    pkg_agg = con.execute(f\"\"\"\n",
    "        SELECT guid,\n",
    "            SUM(nrs) as nrs,\n",
    "            SUM(nrs * mean) / SUM(nrs) as mean,\n",
    "            MAX(max) as max\n",
    "        FROM read_parquet('{pkg_path}')\n",
    "        GROUP BY guid\n",
    "    \"\"\").df()\n",
    "\n",
    "    jr = compute_join_rate(\"system_hw_pkg_power\")\n",
    "    n_pkg = max(int(N_SYNTH * jr), 10)\n",
    "\n",
    "    synth_pkg = dp_histogram_synthesis(\n",
    "        pkg_agg, \"guid\",\n",
    "        num_cols=[\"nrs\", \"mean\", \"max\"],\n",
    "        cat_cols=[],\n",
    "        n_synth=n_pkg, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "    synth_pkg[\"nrs\"] = synth_pkg[\"nrs\"].clip(lower=1).round()\n",
    "    synth_pkg[\"mean\"] = synth_pkg[\"mean\"].clip(lower=0)\n",
    "    synth_pkg[\"max\"] = synth_pkg[[\"mean\", \"max\"]].max(axis=1)\n",
    "    synth_pkg.insert(0, \"guid\", assign_guids(n_pkg, rng)[:n_pkg])\n",
    "\n",
    "    synth_hw[\"system_hw_pkg_power\"] = synth_pkg\n",
    "    synth_table_info(\"system_hw_pkg_power\", synth_pkg, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Battery DC events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_batt = _PT_CACHE[\"system_batt_dc_events\"]\n",
    "    display(Markdown(f\"Loaded cached batt_dc_events: {len(synth_batt):,} rows.\"))\n",
    "else:\n",
    "    batt_path = tables[\"system_batt_dc_events\"][\"path\"]\n",
    "    batt_agg = con.execute(f\"\"\"\n",
    "        SELECT guid,\n",
    "            AVG(duration_mins) as duration_mins,\n",
    "            AVG(num_power_ons) as num_power_ons\n",
    "        FROM read_parquet('{batt_path}')\n",
    "        GROUP BY guid\n",
    "    \"\"\").df()\n",
    "\n",
    "    jr = compute_join_rate(\"system_batt_dc_events\")\n",
    "    n_batt = int(N_SYNTH * jr)\n",
    "\n",
    "    synth_batt = dp_histogram_synthesis(\n",
    "        batt_agg, \"guid\",\n",
    "        num_cols=[\"duration_mins\", \"num_power_ons\"],\n",
    "        cat_cols=[],\n",
    "        n_synth=n_batt, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "    synth_batt[\"duration_mins\"] = synth_batt[\"duration_mins\"].clip(lower=0)\n",
    "    synth_batt[\"num_power_ons\"] = synth_batt[\"num_power_ons\"].clip(lower=0).round()\n",
    "    synth_batt.insert(0, \"guid\", assign_guids(n_batt, rng))\n",
    "\n",
    "    synth_table_info(\"batt_dc_events\", synth_batt, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web cat usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_web_cat = _PT_CACHE[\"system_web_cat_usage\"]\n",
    "    display(Markdown(f\"Loaded cached web_cat_usage: {len(synth_web_cat):,} rows.\"))\n",
    "else:\n",
    "    web_path = tables[\"system_web_cat_usage\"][\"path\"]\n",
    "    web_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, browser,\n",
    "            COUNT(*) as num_instances,\n",
    "            SUM(duration_ms) as duration_ms\n",
    "        FROM read_parquet('{web_path}')\n",
    "        GROUP BY guid, browser\n",
    "    \"\"\").df()\n",
    "\n",
    "    browser_dist = web_agg.groupby(\"browser\").agg(\n",
    "        n_guids=(\"guid\", \"nunique\"),\n",
    "        total_instances=(\"num_instances\", \"sum\"),\n",
    "        total_duration=(\"duration_ms\", \"sum\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    jr = compute_join_rate(\"system_web_cat_usage\")\n",
    "    n_web = int(N_SYNTH * jr)\n",
    "    web_guids = assign_guids(n_web, rng)\n",
    "\n",
    "    browser_counts = browser_dist[\"n_guids\"].values.astype(float)\n",
    "    noise = np.random.laplace(0, 1.0 / TARGET_EPSILON, len(browser_counts))\n",
    "    noisy_browser = np.clip(browser_counts + noise, 0, None)\n",
    "    browser_probs = noisy_browser / noisy_browser.sum()\n",
    "\n",
    "    guid_level_dur = web_agg.groupby(\"guid\")[\"duration_ms\"].sum()\n",
    "    guid_level_inst = web_agg.groupby(\"guid\")[\"num_instances\"].sum()\n",
    "\n",
    "    synth_dur = dp_histogram_synthesis(\n",
    "        pd.DataFrame({\"guid\": guid_level_dur.index, \"duration_ms\": guid_level_dur.values}),\n",
    "        \"guid\", num_cols=[\"duration_ms\"], cat_cols=[], n_synth=n_web, epsilon=TARGET_EPSILON / 2, rng=rng,\n",
    "    )\n",
    "    synth_inst = dp_histogram_synthesis(\n",
    "        pd.DataFrame({\"guid\": guid_level_inst.index, \"num_instances\": guid_level_inst.values}),\n",
    "        \"guid\", num_cols=[\"num_instances\"], cat_cols=[], n_synth=n_web, epsilon=TARGET_EPSILON / 2, rng=rng,\n",
    "    )\n",
    "\n",
    "    avg_browsers_per_guid = web_agg.groupby(\"guid\")[\"browser\"].nunique().mean()\n",
    "    n_browsers_per_guid = rng.poisson(avg_browsers_per_guid, n_web).clip(1, len(browser_dist))\n",
    "\n",
    "    web_rows = []\n",
    "    for i in range(n_web):\n",
    "        nb = n_browsers_per_guid[i]\n",
    "        browsers = rng.choice(browser_dist[\"browser\"].values, size=nb, replace=False, p=browser_probs)\n",
    "        dur_share = rng.dirichlet(np.ones(nb))\n",
    "        inst_share = rng.dirichlet(np.ones(nb))\n",
    "        for j, b in enumerate(browsers):\n",
    "            web_rows.append({\n",
    "                \"guid\": web_guids[i],\n",
    "                \"browser\": b,\n",
    "                \"duration_ms\": max(0, synth_dur[\"duration_ms\"].iloc[i] * dur_share[j]),\n",
    "                \"page_load_count\": max(0, int(synth_inst[\"num_instances\"].iloc[i] * inst_share[j])),\n",
    "            })\n",
    "\n",
    "    synth_web_cat = pd.DataFrame(web_rows)\n",
    "\n",
    "    synth_table_info(\"web_cat_usage\", synth_web_cat, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web cat pivot duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_pivot_data = _PT_CACHE[\"system_web_cat_pivot_duration\"]\n",
    "    display(Markdown(f\"Loaded cached web_cat_pivot_duration: {len(synth_pivot_data):,} rows.\"))\n",
    "else:\n",
    "    pivot_path = tables[\"system_web_cat_pivot_duration\"][\"path\"]\n",
    "    pivot_df = con.execute(f\"SELECT * FROM read_parquet('{pivot_path}')\").df()\n",
    "\n",
    "    cat_cols_pivot = [c for c in pivot_df.columns if c not in [\"guid\", \"dt\"]]\n",
    "\n",
    "    pivot_guid_agg = pivot_df.groupby(\"guid\").agg(\n",
    "        **{c: (c, \"sum\") for c in cat_cols_pivot}\n",
    "    ).reset_index()\n",
    "    pivot_guid_agg[\"days\"] = pivot_df.groupby(\"guid\").size().values\n",
    "\n",
    "    jr = compute_join_rate(\"system_web_cat_pivot_duration\")\n",
    "    n_pivot = int(N_SYNTH * jr)\n",
    "\n",
    "    synth_pivot_data = dp_histogram_synthesis(\n",
    "        pivot_guid_agg, \"guid\",\n",
    "        num_cols=cat_cols_pivot,\n",
    "        cat_cols=[],\n",
    "        n_synth=n_pivot, epsilon=TARGET_EPSILON, rng=rng, n_bins=15,\n",
    "    )\n",
    "\n",
    "    for c in cat_cols_pivot:\n",
    "        synth_pivot_data[c] = synth_pivot_data[c].clip(lower=0)\n",
    "\n",
    "    synth_pivot_data.insert(0, \"guid\", assign_guids(n_pivot, rng))\n",
    "\n",
    "    synth_table_info(\"web_cat_pivot_duration\", synth_pivot_data, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On/off/suspend time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_onoff = _PT_CACHE[\"system_on_off_suspend_time_day\"]\n",
    "    display(Markdown(f\"Loaded cached on_off_suspend_time_day: {len(synth_onoff):,} rows.\"))\n",
    "else:\n",
    "    onoff_path = tables[\"system_on_off_suspend_time_day\"][\"path\"]\n",
    "    onoff_agg = con.execute(f\"\"\"\n",
    "        SELECT guid,\n",
    "            AVG(on_time) as on_time,\n",
    "            AVG(off_time) as off_time,\n",
    "            AVG(mods_time) as mods_time,\n",
    "            AVG(sleep_time) as sleep_time\n",
    "        FROM read_parquet('{onoff_path}')\n",
    "        GROUP BY guid\n",
    "    \"\"\").df()\n",
    "\n",
    "    jr = compute_join_rate(\"system_on_off_suspend_time_day\")\n",
    "    n_onoff = int(N_SYNTH * jr)\n",
    "\n",
    "    synth_onoff = dp_histogram_synthesis(\n",
    "        onoff_agg, \"guid\",\n",
    "        num_cols=[\"on_time\", \"off_time\", \"mods_time\", \"sleep_time\"],\n",
    "        cat_cols=[],\n",
    "        n_synth=n_onoff, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "    for c in [\"on_time\", \"off_time\", \"mods_time\", \"sleep_time\"]:\n",
    "        synth_onoff[c] = synth_onoff[c].clip(lower=0)\n",
    "    synth_onoff.insert(0, \"guid\", assign_guids(n_onoff, rng))\n",
    "\n",
    "    synth_table_info(\"on_off_suspend_time_day\", synth_onoff, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_disp = _PT_CACHE[\"system_display_devices\"]\n",
    "    display(Markdown(f\"Loaded cached display_devices: {len(synth_disp):,} rows.\"))\n",
    "else:\n",
    "    disp_path = tables[\"system_display_devices\"][\"path\"]\n",
    "    disp_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, connection_type, vendor_name,\n",
    "            resolution_width, resolution_heigth,\n",
    "            AVG(duration_ac) as duration_ac,\n",
    "            AVG(duration_dc) as duration_dc\n",
    "        FROM read_parquet('{disp_path}')\n",
    "        WHERE connection_type IS NOT NULL\n",
    "        GROUP BY guid, connection_type, vendor_name, resolution_width, resolution_heigth\n",
    "    \"\"\").df()\n",
    "\n",
    "    disp_cats = [\"connection_type\", \"vendor_name\"]\n",
    "    disp_nums = [\"resolution_width\", \"resolution_heigth\", \"duration_ac\", \"duration_dc\"]\n",
    "\n",
    "    jr = compute_join_rate(\"system_display_devices\")\n",
    "    n_disp = int(N_SYNTH * jr)\n",
    "\n",
    "    synth_disp = dp_histogram_synthesis(\n",
    "        disp_agg, \"guid\",\n",
    "        num_cols=disp_nums,\n",
    "        cat_cols=disp_cats,\n",
    "        n_synth=n_disp, epsilon=TARGET_EPSILON, rng=rng,\n",
    "    )\n",
    "    synth_disp[\"resolution_width\"] = synth_disp[\"resolution_width\"].clip(lower=0).round().astype(int)\n",
    "    synth_disp[\"resolution_heigth\"] = synth_disp[\"resolution_heigth\"].clip(lower=0).round().astype(int)\n",
    "    synth_disp[\"duration_ac\"] = synth_disp[\"duration_ac\"].clip(lower=0)\n",
    "    synth_disp[\"duration_dc\"] = synth_disp[\"duration_dc\"].clip(lower=0)\n",
    "    synth_disp.insert(0, \"guid\", assign_guids(n_disp, rng))\n",
    "\n",
    "    synth_table_info(\"display_devices\", synth_disp, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Userwait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_userwait = _PT_CACHE[\"system_userwait\"]\n",
    "    display(Markdown(f\"Loaded cached userwait: {len(synth_userwait):,} rows.\"))\n",
    "else:\n",
    "    uw_path = tables[\"system_userwait\"][\"path\"]\n",
    "    uw_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, proc_name, event_name, acdc,\n",
    "            SUM(number_of_instances) as number_of_instances,\n",
    "            SUM(total_duration_ms) as total_duration_ms\n",
    "        FROM read_parquet('{uw_path}')\n",
    "        GROUP BY guid, proc_name, event_name, acdc\n",
    "    \"\"\").df()\n",
    "\n",
    "    proc_dist = uw_agg.groupby(\"proc_name\")[\"guid\"].nunique().reset_index(name=\"n_guids\")\n",
    "    proc_dist = proc_dist.sort_values(\"n_guids\", ascending=False).head(200)\n",
    "\n",
    "    event_dist = uw_agg[\"event_name\"].value_counts(normalize=True)\n",
    "    acdc_dist = uw_agg[\"acdc\"].value_counts(normalize=True)\n",
    "\n",
    "    noise_proc = np.random.laplace(0, 1.0 / TARGET_EPSILON, len(proc_dist))\n",
    "    noisy_proc = np.clip(proc_dist[\"n_guids\"].values.astype(float) + noise_proc, 0, None)\n",
    "    proc_probs = noisy_proc / noisy_proc.sum()\n",
    "\n",
    "    dur_per_proc = uw_agg.groupby(\"proc_name\")[\"total_duration_ms\"].mean()\n",
    "    inst_per_proc = uw_agg.groupby(\"proc_name\")[\"number_of_instances\"].mean()\n",
    "\n",
    "    jr = compute_join_rate(\"system_userwait\")\n",
    "    n_uw = int(N_SYNTH * jr)\n",
    "    uw_guids = assign_guids(n_uw, rng)\n",
    "\n",
    "    avg_procs_per_guid = uw_agg.groupby(\"guid\")[\"proc_name\"].nunique().median()\n",
    "    n_procs_per_guid = rng.poisson(avg_procs_per_guid, n_uw).clip(1, 50)\n",
    "\n",
    "    uw_rows = []\n",
    "    for i in range(n_uw):\n",
    "        np_ = n_procs_per_guid[i]\n",
    "        procs = rng.choice(proc_dist[\"proc_name\"].values, size=np_, replace=False, p=proc_probs)\n",
    "        for p in procs:\n",
    "            mean_dur = dur_per_proc.get(p, 1000.0)\n",
    "            mean_inst = inst_per_proc.get(p, 10.0)\n",
    "            ev = rng.choice(event_dist.index, p=event_dist.values)\n",
    "            ac = rng.choice(acdc_dist.index, p=acdc_dist.values)\n",
    "            uw_rows.append({\n",
    "                \"guid\": uw_guids[i],\n",
    "                \"proc_name\": p,\n",
    "                \"event_name\": ev,\n",
    "                \"acdc\": ac,\n",
    "                \"ac_dc_event_name\": ac,\n",
    "                \"number_of_instances\": max(1, int(rng.exponential(mean_inst))),\n",
    "                \"total_duration_ms\": max(0, rng.exponential(mean_dur)),\n",
    "            })\n",
    "\n",
    "    synth_userwait = pd.DataFrame(uw_rows)\n",
    "\n",
    "    synth_table_info(\"userwait\", synth_userwait, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foreground apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_frgnd = _PT_CACHE[\"system_frgnd_apps_types\"]\n",
    "    display(Markdown(f\"Loaded cached frgnd_apps_types: {len(synth_frgnd):,} rows.\"))\n",
    "else:\n",
    "    frgnd_path = tables[\"system_frgnd_apps_types\"][\"path\"]\n",
    "    frgnd_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, app_type, exe_name,\n",
    "            AVG(totalsecfocal_day) as totalsecfocal_day,\n",
    "            SUM(lines_per_day) as lines_per_day\n",
    "        FROM read_parquet('{frgnd_path}')\n",
    "        GROUP BY guid, app_type, exe_name\n",
    "    \"\"\").df()\n",
    "\n",
    "    app_type_dist = frgnd_agg[\"app_type\"].value_counts(normalize=True)\n",
    "    exe_by_type = frgnd_agg.groupby(\"app_type\")[\"exe_name\"].apply(lambda x: x.value_counts().head(50).index.tolist()).to_dict()\n",
    "    focal_by_exe = frgnd_agg.groupby(\"exe_name\")[\"totalsecfocal_day\"].mean().to_dict()\n",
    "    lines_by_exe = frgnd_agg.groupby(\"exe_name\")[\"lines_per_day\"].mean().to_dict()\n",
    "\n",
    "    jr = compute_join_rate(\"system_frgnd_apps_types\")\n",
    "    n_frgnd = int(N_SYNTH * jr)\n",
    "    frgnd_guids = assign_guids(n_frgnd, rng)\n",
    "\n",
    "    avg_apps_per_guid = frgnd_agg.groupby(\"guid\").size().median()\n",
    "    n_apps_per_guid = rng.poisson(avg_apps_per_guid, n_frgnd).clip(1, 100)\n",
    "\n",
    "    noise_type = np.random.laplace(0, 1.0 / TARGET_EPSILON, len(app_type_dist))\n",
    "    noisy_type_counts = np.clip(app_type_dist.values * len(frgnd_agg) + noise_type, 0, None)\n",
    "    type_probs = noisy_type_counts / noisy_type_counts.sum()\n",
    "\n",
    "    frgnd_rows = []\n",
    "    for i in range(n_frgnd):\n",
    "        na = n_apps_per_guid[i]\n",
    "        for _ in range(na):\n",
    "            at = rng.choice(app_type_dist.index, p=type_probs)\n",
    "            exes = exe_by_type.get(at, [\"unknown.exe\"])\n",
    "            exe = rng.choice(exes)\n",
    "            frgnd_rows.append({\n",
    "                \"guid\": frgnd_guids[i],\n",
    "                \"app_type\": at,\n",
    "                \"exe_name\": exe,\n",
    "                \"totalsecfocal_day\": max(0, rng.exponential(focal_by_exe.get(exe, 100.0))),\n",
    "                \"lines_per_day\": max(0, rng.exponential(lines_by_exe.get(exe, 10.0))),\n",
    "            })\n",
    "\n",
    "    synth_frgnd = pd.DataFrame(frgnd_rows)\n",
    "\n",
    "    synth_table_info(\"frgnd_apps_types\", synth_frgnd, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mods top blocker hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_blocker = _PT_CACHE[\"system_mods_top_blocker_hist\"]\n",
    "    display(Markdown(f\"Loaded cached mods_top_blocker_hist: {len(synth_blocker):,} rows.\"))\n",
    "else:\n",
    "    blocker_path = tables[\"system_mods_top_blocker_hist\"][\"path\"]\n",
    "    blocker_agg = con.execute(f\"\"\"\n",
    "        SELECT guid, dt, blocker_name, blocker_type, activity_level,\n",
    "            AVG(active_time_ms) as active_time_ms\n",
    "        FROM read_parquet('{blocker_path}')\n",
    "        GROUP BY guid, dt, blocker_name, blocker_type, activity_level\n",
    "    \"\"\").df()\n",
    "\n",
    "    blocker_name_dist = blocker_agg[\"blocker_name\"].value_counts(normalize=True).head(100)\n",
    "    blocker_type_dist = blocker_agg[\"blocker_type\"].value_counts(normalize=True)\n",
    "    activity_dist = blocker_agg[\"activity_level\"].fillna(\"Unknown\").astype(str).value_counts(normalize=True)\n",
    "    dur_by_blocker = blocker_agg.groupby(\"blocker_name\")[\"active_time_ms\"].mean().to_dict()\n",
    "\n",
    "    noise_bn = np.random.laplace(0, 1.0 / TARGET_EPSILON, len(blocker_name_dist))\n",
    "    noisy_bn = np.clip(blocker_name_dist.values * len(blocker_agg) + noise_bn, 0, None)\n",
    "    bn_probs = noisy_bn / noisy_bn.sum()\n",
    "\n",
    "    jr = compute_join_rate(\"system_mods_top_blocker_hist\")\n",
    "    n_blocker = int(N_SYNTH * jr)\n",
    "    blocker_guids = assign_guids(n_blocker, rng)\n",
    "\n",
    "    avg_entries_per_guid = blocker_agg.groupby(\"guid\").size().median()\n",
    "    n_entries = rng.poisson(avg_entries_per_guid, n_blocker).clip(1, 200)\n",
    "\n",
    "    real_dt_values = blocker_agg[\"dt\"].dropna().values\n",
    "\n",
    "    blocker_rows = []\n",
    "    for i in range(n_blocker):\n",
    "        ne = n_entries[i]\n",
    "        for _ in range(ne):\n",
    "            bn = rng.choice(blocker_name_dist.index, p=bn_probs)\n",
    "            bt = rng.choice(blocker_type_dist.index, p=blocker_type_dist.values)\n",
    "            al = rng.choice(activity_dist.index, p=activity_dist.values)\n",
    "            blocker_rows.append({\n",
    "                \"guid\": blocker_guids[i],\n",
    "                \"dt\": rng.choice(real_dt_values),\n",
    "                \"blocker_name\": bn,\n",
    "                \"blocker_type\": bt,\n",
    "                \"activity_level\": al,\n",
    "                \"active_time_ms\": max(0, rng.exponential(dur_by_blocker.get(bn, 5000.0))),\n",
    "            })\n",
    "\n",
    "    synth_blocker = pd.DataFrame(blocker_rows)\n",
    "\n",
    "    synth_table_info(\"mods_top_blocker_hist\", synth_blocker, jr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mods power consumption (stub data, 1 guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    synth_power = _PT_CACHE[\"system_mods_power_consumption\"]\n",
    "    display(Markdown(f\"Loaded cached mods_power_consumption: {len(synth_power):,} rows.\"))\n",
    "else:\n",
    "    power_path = tables[\"system_mods_power_consumption\"][\"path\"]\n",
    "    power_df = con.execute(f\"\"\"\n",
    "        SELECT user_id, app_id, total_power_consumption\n",
    "        FROM read_parquet('{power_path}')\n",
    "    \"\"\").df()\n",
    "\n",
    "    synth_power = power_df.copy()\n",
    "    noise = np.random.laplace(0, 1.0 / TARGET_EPSILON, len(synth_power))\n",
    "    synth_power[\"total_power_consumption\"] = (synth_power[\"total_power_consumption\"] + noise).clip(lower=0)\n",
    "\n",
    "    display(Markdown(f\"mods_power_consumption: copied stub ({len(synth_power)} rows, 1 guid) with Laplace noise.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Save all synthetic tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _PERTABLE_CACHED:\n",
    "    display(Markdown(f\"All {len(_PT_CACHE)} synthetic tables already saved in `{SYNTH_DIR}`.\"))\n",
    "else:\n",
    "    synth_tables = {\n",
    "        \"system_sysinfo_unique_normalized\": synth_sysinfo,\n",
    "        \"system_cpu_metadata\": synth_cpu,\n",
    "        \"system_os_codename_history\": synth_os,\n",
    "        \"system_network_consumption\": synth_network,\n",
    "        \"system_memory_utilization\": synth_memory,\n",
    "        \"system_batt_dc_events\": synth_batt,\n",
    "        \"system_web_cat_usage\": synth_web_cat,\n",
    "        \"system_web_cat_pivot_duration\": synth_pivot_data,\n",
    "        \"system_on_off_suspend_time_day\": synth_onoff,\n",
    "        \"system_display_devices\": synth_disp,\n",
    "        \"system_userwait\": synth_userwait,\n",
    "        \"system_frgnd_apps_types\": synth_frgnd,\n",
    "        \"system_mods_top_blocker_hist\": synth_blocker,\n",
    "        \"system_mods_power_consumption\": synth_power,\n",
    "    }\n",
    "\n",
    "    for tname, hw_df in synth_hw.items():\n",
    "        synth_tables[tname] = hw_df\n",
    "\n",
    "    save_rows = []\n",
    "    for name, df in synth_tables.items():\n",
    "        path = SYNTH_DIR / f\"{name}.parquet\"\n",
    "        df.to_parquet(path, index=False)\n",
    "        save_rows.append({\"table\": name, \"rows\": len(df), \"cols\": len(df.columns)})\n",
    "\n",
    "    display(Markdown(f\"Saved {len(synth_tables)} synthetic tables to `{SYNTH_DIR}`.\"))\n",
    "    display(pd.DataFrame(save_rows).sort_values(\"rows\", ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Run benchmark queries on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "from src.eval.benchmark import run_benchmark\n",
    "\n",
    "INFEASIBLE = [\n",
    "    \"ranked_process_classifications\",\n",
    "    \"top_10_processes_per_user_id_ranked_by_total_power_consumption\",\n",
    "    \"top_20_most_power_consuming_processes_by_avg_power_consumed\",\n",
    "]\n",
    "\n",
    "query_names = [f.stem for f in QUERIES_DIR.glob(\"*.json\") if f.stem not in INFEASIBLE]\n",
    "\n",
    "display(Markdown(f\"Running {len(query_names)} benchmark queries on synthetic data.\"))\n",
    "\n",
    "synth_results = run_benchmark(query_names, QUERIES_DIR, SYNTH_DIR, RESULTS_SYNTH)\n",
    "\n",
    "display(Markdown(f\"{len(synth_results)}/{len(query_names)} queries executed successfully.\"))\n",
    "\n",
    "failed = [q for q in query_names if q not in synth_results]\n",
    "if failed:\n",
    "    display(Markdown(f\"Failed queries: {', '.join(failed)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Compare synthetic vs real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(real_val, synth_val):\n",
    "    if abs(real_val) < 1e-10:\n",
    "        return float(\"inf\") if abs(synth_val) > 1e-10 else 0.0\n",
    "    return abs(real_val - synth_val) / abs(real_val)\n",
    "\n",
    "\n",
    "def compare_scalar_columns(real_df, synth_df, query_name):\n",
    "    rows = []\n",
    "    numeric_cols = real_df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if col in synth_df.columns:\n",
    "            r_mean = real_df[col].mean()\n",
    "            s_mean = synth_df[col].mean()\n",
    "            re = relative_error(r_mean, s_mean)\n",
    "            rows.append({\n",
    "                \"query\": query_name,\n",
    "                \"column\": col,\n",
    "                \"real_mean\": round(r_mean, 4),\n",
    "                \"synth_mean\": round(s_mean, 4),\n",
    "                \"rel_error\": round(re, 4),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "\n",
    "def compare_rankings(real_df, synth_df, query_name, rank_col, value_col):\n",
    "    if rank_col not in real_df.columns or rank_col not in synth_df.columns:\n",
    "        return []\n",
    "    if value_col not in real_df.columns or value_col not in synth_df.columns:\n",
    "        return []\n",
    "\n",
    "    real_ranked = set(real_df[value_col].astype(str).head(10).values)\n",
    "    synth_ranked = set(synth_df[value_col].astype(str).head(10).values)\n",
    "    overlap = len(real_ranked & synth_ranked)\n",
    "\n",
    "    return [{\n",
    "        \"query\": query_name,\n",
    "        \"metric\": f\"top-10 {value_col} overlap\",\n",
    "        \"value\": f\"{overlap}/10\",\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comparisons = []\n",
    "all_ranking_comparisons = []\n",
    "\n",
    "for qname, synth_df in synth_results.items():\n",
    "    real_csv = RESULTS_REAL / f\"{qname}.csv\"\n",
    "    if not real_csv.exists():\n",
    "        continue\n",
    "    real_df = pd.read_csv(real_csv)\n",
    "\n",
    "    all_comparisons.extend(compare_scalar_columns(real_df, synth_df, qname))\n",
    "\n",
    "comparison_df = pd.DataFrame(all_comparisons)\n",
    "\n",
    "if len(comparison_df) > 0:\n",
    "    display(Markdown(f\"Scalar column comparison across {comparison_df['query'].nunique()} queries, {len(comparison_df)} column comparisons.\"))\n",
    "\n",
    "    within_10 = (comparison_df[\"rel_error\"] <= 0.10).sum()\n",
    "    within_25 = (comparison_df[\"rel_error\"] <= 0.25).sum()\n",
    "    within_50 = (comparison_df[\"rel_error\"] <= 0.50).sum()\n",
    "    total = len(comparison_df)\n",
    "\n",
    "    display(Markdown(\n",
    "        f\"Accuracy summary: {within_10}/{total} columns within 10%, \"\n",
    "        f\"{within_25}/{total} within 25%, {within_50}/{total} within 50%.\"\n",
    "    ))\n",
    "\n",
    "    display(comparison_df.sort_values(\"rel_error\").head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"Per-query relative error summary (mean across numeric columns):\"))\n",
    "\n",
    "if len(comparison_df) > 0:\n",
    "    per_query = comparison_df.groupby(\"query\").agg(\n",
    "        n_cols=(\"column\", \"count\"),\n",
    "        mean_rel_error=(\"rel_error\", lambda x: round(x[x < float(\"inf\")].mean(), 4)),\n",
    "        median_rel_error=(\"rel_error\", lambda x: round(x[x < float(\"inf\")].median(), 4)),\n",
    "        min_rel_error=(\"rel_error\", lambda x: round(x[x < float(\"inf\")].min(), 4)),\n",
    "        max_rel_error=(\"rel_error\", lambda x: round(x[x < float(\"inf\")].max(), 4) if len(x[x < float(\"inf\")]) > 0 else float(\"inf\")),\n",
    "        pct_within_25=(\"rel_error\", lambda x: round((x <= 0.25).mean() * 100, 1)),\n",
    "    ).sort_values(\"mean_rel_error\").reset_index()\n",
    "\n",
    "    display(per_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"Worst columns (highest relative error):\"))\n",
    "\n",
    "if len(comparison_df) > 0:\n",
    "    worst = comparison_df[comparison_df[\"rel_error\"] < float(\"inf\")].sort_values(\"rel_error\", ascending=False).head(20)\n",
    "    display(worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: Qualitative spot checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Browser popularity (popular_browsers_by_count_usage_percentage)\"))\n",
    "\n",
    "if \"popular_browsers_by_count_usage_percentage\" in synth_results:\n",
    "    real_browsers = pd.read_csv(RESULTS_REAL / \"popular_browsers_by_count_usage_percentage.csv\")\n",
    "    synth_browsers = synth_results[\"popular_browsers_by_count_usage_percentage\"]\n",
    "\n",
    "    display(Markdown(\"Real:\"))\n",
    "    display(real_browsers)\n",
    "    display(Markdown(\"Synthetic:\"))\n",
    "    display(synth_browsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### RAM utilization histogram (ram_utilization_histogram)\"))\n",
    "\n",
    "if \"ram_utilization_histogram\" in synth_results:\n",
    "    real_ram = pd.read_csv(RESULTS_REAL / \"ram_utilization_histogram.csv\")\n",
    "    synth_ram = synth_results[\"ram_utilization_histogram\"]\n",
    "\n",
    "    display(Markdown(\"Real:\"))\n",
    "    display(real_ram)\n",
    "    display(Markdown(\"Synthetic:\"))\n",
    "    display(synth_ram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Most popular browser by country (most_popular_browser_in_each_country_by_system_count)\"))\n",
    "\n",
    "if \"most_popular_browser_in_each_country_by_system_count\" in synth_results:\n",
    "    real_bc = pd.read_csv(RESULTS_REAL / \"most_popular_browser_in_each_country_by_system_count.csv\")\n",
    "    synth_bc = synth_results[\"most_popular_browser_in_each_country_by_system_count\"]\n",
    "\n",
    "    merged = real_bc.merge(synth_bc, on=\"country\", suffixes=(\"_real\", \"_synth\"), how=\"outer\")\n",
    "    merged[\"match\"] = merged[\"browser_real\"] == merged[\"browser_synth\"]\n",
    "\n",
    "    n_match = merged[\"match\"].sum()\n",
    "    n_total = len(merged.dropna(subset=[\"browser_real\", \"browser_synth\"]))\n",
    "\n",
    "    display(Markdown(f\"Browser ranking match: {n_match}/{n_total} countries got the correct top browser.\"))\n",
    "    display(merged.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"### Platform power by chassis (avg_platform_power_c0_freq_temp_by_chassis)\"))\n",
    "\n",
    "if \"avg_platform_power_c0_freq_temp_by_chassis\" in synth_results:\n",
    "    real_chassis = pd.read_csv(RESULTS_REAL / \"avg_platform_power_c0_freq_temp_by_chassis.csv\")\n",
    "    synth_chassis = synth_results[\"avg_platform_power_c0_freq_temp_by_chassis\"]\n",
    "\n",
    "    display(Markdown(\"Real:\"))\n",
    "    display(real_chassis)\n",
    "    display(Markdown(\"Synthetic:\"))\n",
    "    display(synth_chassis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Per-table DP-SGD synthesis eliminates the sparsity problem from the wide-table approach. Each table is synthesized from its own data (no 93% zeros), so continuous metrics preserve realistic distributions. The cost is the loss of cross-table correlations: JOINs between synthetic tables produce random associations because guid assignment is independent per table.\n",
    "\n",
    "The total privacy budget under basic composition is k * epsilon for k tables. With 19 tables at epsilon=4.0 each, the composed guarantee is (76, delta)-DP. This is a known limitation of per-table synthesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}