{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29eb199",
   "metadata": {},
   "source": [
    "# 11. Additive Postprocessing Experiment\n",
    "\n",
    "This notebook runs additive postprocessing on synthetic reporting tables without changing existing notebooks or baseline outputs.\n",
    "\n",
    "Outputs are written to `data/experiments_additive/postprocess_*`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6082d32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T23:33:42.016383Z",
     "iopub.status.busy": "2026-02-12T23:33:42.016168Z",
     "iopub.status.idle": "2026-02-12T23:33:43.561957Z",
     "shell.execute_reply": "2026-02-12T23:33:43.561351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Project root: `/Users/enscribe/Repositories/School/dsc180-q2`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "ROOT = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd().resolve()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from src.experiments.postprocess_reporting import PostprocessConfig, postprocess_reporting_dir\n",
    "from src.pipeline.run_benchmark import run_all\n",
    "from src.eval.compare import evaluate_all, results_to_dataframe\n",
    "\n",
    "REAL_REPORTING_DIR = ROOT / 'data' / 'reporting'\n",
    "REAL_RESULTS_DIR = ROOT / 'data' / 'results' / 'real'\n",
    "QUERIES_DIR = ROOT / 'docs' / 'queries'\n",
    "OUT_ROOT = ROOT / 'data' / 'experiments_additive'\n",
    "\n",
    "display(Markdown(f\"Project root: `{ROOT}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16aebdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T23:33:43.563882Z",
     "iopub.status.busy": "2026-02-12T23:33:43.563681Z",
     "iopub.status.idle": "2026-02-12T23:34:36.922773Z",
     "shell.execute_reply": "2026-02-12T23:34:36.922134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FAIL battery_on_duration_cpu_family_gen: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_cpu_metadata.parquet\"\n",
      "\n",
      "LINE 1: ..., avg(duration_mins) as avg_duration_mins_on_battery from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                     ^\n",
      "  FAIL display_devices_connection_type_resolution_durations_ac_dc: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_display_devices.parquet\"\n",
      "\n",
      "LINE 1: ...(avg(duration_dc),2) as average_duration_on_dc_in_seconds from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                          ^\n",
      "  FAIL display_devices_vendors_percentage: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_display_devices.parquet\"\n",
      "\n",
      "LINE 1: ....0/ total_number_of_systems,2 )as percentage_of_systems from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                        ^\n",
      "  FAIL mods_blockers_by_osname_and_codename: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_mods_top_blocker_hist.parquet\"\n",
      "\n",
      "LINE 1: ... (select a.guid, min_ts, max_ts, os_name, os_codename, dt from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                          ^\n",
      "  FAIL on_off_mods_sleep_summary_by_cpu_marketcodename_gen: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_cpu_metadata.parquet\"\n",
      "\n",
      "LINE 1: ...ting/system_on_off_suspend_time_day.parquet') a inner join read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                      ^\n",
      "  FAIL server_exploration_1: Binder Error: Table \"b\" does not have a column named \"model_normalized\"\n",
      "\n",
      "Candidate bindings: : \"modelvendor_normalized\"\n",
      "\n",
      "LINE 1: ..._bytes, b.chassistype, b.modelvendor_normalized as vendor, b.model_normalized as model, b.ram, b.os, b.\"#ofcores\" as...\n",
      "                                                                      ^\n",
      "  FAIL top_10_applications_by_app_type_ranked_by_focal_time: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_frgnd_apps_types.parquet\"\n",
      "\n",
      "LINE 1: ... app_type order by avg(totalsecfocal_day) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                        ^\n",
      "  FAIL top_10_applications_by_app_type_ranked_by_system_count: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_frgnd_apps_types.parquet\"\n",
      "\n",
      "LINE 1: ... by app_type order by count(distinct guid) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                         ^\n",
      "  FAIL top_10_applications_by_app_type_ranked_by_total_detections: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_frgnd_apps_types.parquet\"\n",
      "\n",
      "LINE 1: ... by app_type order by sum(lines_per_day) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                       ^\n",
      "  FAIL top_mods_blocker_types_durations_by_osname_and_codename: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_mods_top_blocker_hist.parquet\"\n",
      "\n",
      "LINE 1: ..., activity_level, blocker_type, os_name, os_codename from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                     ^\n",
      "  FAIL userwait_top_10_wait_processes: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_userwait.parquet\"\n",
      "\n",
      "LINE 1: ...tion_ms/1000))/sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                      ^\n",
      "  FAIL userwait_top_10_wait_processes_wait_type_ac_dc: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_userwait.parquet\"\n",
      "\n",
      "LINE 1: ...tion_ms/1000))/sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                      ^\n",
      "  FAIL userwait_top_20_wait_processes_compare_ac_dc_unknown_durations: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/postprocess_pe_refcats/reporting/system_userwait.parquet\"\n",
      "\n",
      "LINE 1: ... / 1000)) / sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
      "                                                                   ^\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Additive run summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>tables_written</th>\n",
       "      <th>queries_evaluated</th>\n",
       "      <th>queries_passed</th>\n",
       "      <th>pass_rate</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>evaluation_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mst_refcats</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pertable_refcats</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.303107</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pe_refcats</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                run  tables_written  queries_evaluated  queries_passed  \\\n",
       "1       mst_refcats              18                 21               6   \n",
       "0  pertable_refcats              19                 21               6   \n",
       "2        pe_refcats              12                  8               2   \n",
       "\n",
       "   pass_rate  avg_score                                     evaluation_csv  \n",
       "1   0.285714   0.328326  /Users/enscribe/Repositories/School/dsc180-q2/...  \n",
       "0   0.285714   0.303107  /Users/enscribe/Repositories/School/dsc180-q2/...  \n",
       "2   0.250000   0.149866  /Users/enscribe/Repositories/School/dsc180-q2/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runs = {\n",
    "    'pertable_refcats': {\n",
    "        'synth_reporting_dir': ROOT / 'data' / 'reporting' / 'synth_pertable',\n",
    "        'cfg': PostprocessConfig(use_reference_categories=True, fuzzy_cutoff=0.80),\n",
    "    },\n",
    "    'mst_refcats': {\n",
    "        'synth_reporting_dir': ROOT / 'data' / 'reporting' / 'synth_mst',\n",
    "        'cfg': PostprocessConfig(use_reference_categories=True, fuzzy_cutoff=0.80),\n",
    "    },\n",
    "    'pe_refcats': {\n",
    "        'synth_reporting_dir': ROOT / 'data' / 'reporting' / 'pe',\n",
    "        'cfg': PostprocessConfig(use_reference_categories=True, fuzzy_cutoff=0.80),\n",
    "    },\n",
    "}\n",
    "\n",
    "summary_rows = []\n",
    "for name, spec in runs.items():\n",
    "    out_dir = OUT_ROOT / f'postprocess_{name}'\n",
    "    post_dir = out_dir / 'reporting'\n",
    "    query_dir = out_dir / 'query_results'\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    written = postprocess_reporting_dir(\n",
    "        real_reporting_dir=REAL_REPORTING_DIR,\n",
    "        synth_reporting_dir=spec['synth_reporting_dir'],\n",
    "        output_dir=post_dir,\n",
    "        cfg=spec['cfg'],\n",
    "    )\n",
    "\n",
    "    run_all(\n",
    "        queries_dir=QUERIES_DIR,\n",
    "        reporting_dir=post_dir,\n",
    "        output_dir=query_dir,\n",
    "        skip_infeasible=True,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    eval_results = evaluate_all(REAL_RESULTS_DIR, query_dir)\n",
    "    eval_df = results_to_dataframe(eval_results)\n",
    "    eval_df.to_csv(out_dir / 'evaluation.csv', index=False)\n",
    "\n",
    "    ev = eval_df[eval_df['n_metrics'] > 0]\n",
    "    passed = int(ev['passed'].fillna(False).sum()) if len(ev) else 0\n",
    "    avg_score = float(ev['score'].mean()) if len(ev) else 0.0\n",
    "    summary_rows.append({\n",
    "        'run': name,\n",
    "        'tables_written': len(written),\n",
    "        'queries_evaluated': len(ev),\n",
    "        'queries_passed': passed,\n",
    "        'pass_rate': passed / len(ev) if len(ev) else 0.0,\n",
    "        'avg_score': avg_score,\n",
    "        'evaluation_csv': str(out_dir / 'evaluation.csv'),\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_rows).sort_values(['queries_passed', 'avg_score'], ascending=False)\n",
    "display(Markdown('## Additive run summary'))\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bcc11a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T23:34:36.924580Z",
     "iopub.status.busy": "2026-02-12T23:34:36.924436Z",
     "iopub.status.idle": "2026-02-12T23:34:36.938342Z",
     "shell.execute_reply": "2026-02-12T23:34:36.937839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Baseline summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>queries_evaluated</th>\n",
       "      <th>queries_passed</th>\n",
       "      <th>pass_rate</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>evaluation_csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mst_baseline</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pertable_baseline</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.303107</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pe_baseline</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>widetable_baseline</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  run  queries_evaluated  queries_passed  pass_rate  \\\n",
       "1        mst_baseline                 21               6   0.285714   \n",
       "0   pertable_baseline                 21               6   0.285714   \n",
       "2         pe_baseline                  8               2   0.250000   \n",
       "3  widetable_baseline                  8               1   0.125000   \n",
       "\n",
       "   avg_score                                     evaluation_csv  \n",
       "1   0.328326  /Users/enscribe/Repositories/School/dsc180-q2/...  \n",
       "0   0.303107  /Users/enscribe/Repositories/School/dsc180-q2/...  \n",
       "2   0.149866  /Users/enscribe/Repositories/School/dsc180-q2/...  \n",
       "3   0.258065  /Users/enscribe/Repositories/School/dsc180-q2/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_files = {\n",
    "    'pertable_baseline': ROOT / 'data' / 'results' / 'evaluation_pertable.csv',\n",
    "    'mst_baseline': ROOT / 'data' / 'results' / 'evaluation_mst.csv',\n",
    "    'pe_baseline': ROOT / 'data' / 'results' / 'evaluation_pe.csv',\n",
    "    'widetable_baseline': ROOT / 'data' / 'results' / 'evaluation_widetable.csv',\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for label, path in baseline_files.items():\n",
    "    if not path.exists():\n",
    "        continue\n",
    "    df = pd.read_csv(path)\n",
    "    ev = df[df['n_metrics'] > 0]\n",
    "    passed = int(ev['passed'].fillna(False).sum()) if len(ev) else 0\n",
    "    rows.append({\n",
    "        'run': label,\n",
    "        'queries_evaluated': len(ev),\n",
    "        'queries_passed': passed,\n",
    "        'pass_rate': passed / len(ev) if len(ev) else 0.0,\n",
    "        'avg_score': float(ev['score'].mean()) if len(ev) else 0.0,\n",
    "        'evaluation_csv': str(path),\n",
    "    })\n",
    "\n",
    "baseline_summary = pd.DataFrame(rows)\n",
    "display(Markdown('## Baseline summary'))\n",
    "display(baseline_summary.sort_values(['queries_passed', 'avg_score'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de83a3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T23:34:36.939855Z",
     "iopub.status.busy": "2026-02-12T23:34:36.939736Z",
     "iopub.status.idle": "2026-02-12T23:34:36.953674Z",
     "shell.execute_reply": "2026-02-12T23:34:36.953247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Delta vs baseline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>baseline_passed</th>\n",
       "      <th>new_passed</th>\n",
       "      <th>delta_passed</th>\n",
       "      <th>baseline_avg_score</th>\n",
       "      <th>new_avg_score</th>\n",
       "      <th>delta_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pertable_refcats</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303107</td>\n",
       "      <td>0.303107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mst_refcats</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pe_refcats</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                run  baseline_passed  new_passed  delta_passed  \\\n",
       "0  pertable_refcats                6           6             0   \n",
       "1       mst_refcats                6           6             0   \n",
       "2        pe_refcats                2           2             0   \n",
       "\n",
       "   baseline_avg_score  new_avg_score  delta_avg_score  \n",
       "0            0.303107       0.303107              0.0  \n",
       "1            0.328326       0.328326              0.0  \n",
       "2            0.149866       0.149866              0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta_rows = []\n",
    "mapping = {\n",
    "    'pertable_refcats': ROOT / 'data' / 'results' / 'evaluation_pertable.csv',\n",
    "    'mst_refcats': ROOT / 'data' / 'results' / 'evaluation_mst.csv',\n",
    "    'pe_refcats': ROOT / 'data' / 'results' / 'evaluation_pe.csv',\n",
    "}\n",
    "\n",
    "for run_name, baseline_path in mapping.items():\n",
    "    new_path = OUT_ROOT / f'postprocess_{run_name}' / 'evaluation.csv'\n",
    "    if not baseline_path.exists() or not new_path.exists():\n",
    "        continue\n",
    "\n",
    "    b = pd.read_csv(baseline_path)\n",
    "    n = pd.read_csv(new_path)\n",
    "\n",
    "    b_ev = b[b['n_metrics'] > 0].copy()\n",
    "    n_ev = n[n['n_metrics'] > 0].copy()\n",
    "\n",
    "    b_pass = int(b_ev['passed'].fillna(False).sum())\n",
    "    n_pass = int(n_ev['passed'].fillna(False).sum())\n",
    "    b_avg = float(b_ev['score'].mean()) if len(b_ev) else 0.0\n",
    "    n_avg = float(n_ev['score'].mean()) if len(n_ev) else 0.0\n",
    "\n",
    "    delta_rows.append({\n",
    "        'run': run_name,\n",
    "        'baseline_passed': b_pass,\n",
    "        'new_passed': n_pass,\n",
    "        'delta_passed': n_pass - b_pass,\n",
    "        'baseline_avg_score': b_avg,\n",
    "        'new_avg_score': n_avg,\n",
    "        'delta_avg_score': n_avg - b_avg,\n",
    "    })\n",
    "\n",
    "delta_df = pd.DataFrame(delta_rows).sort_values('delta_avg_score', ascending=False)\n",
    "display(Markdown('## Delta vs baseline'))\n",
    "display(delta_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
