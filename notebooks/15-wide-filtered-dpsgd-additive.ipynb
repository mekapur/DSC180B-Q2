{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 15. Wide-Filtered DP-SGD (Additive)\n",
        "\n",
        "This notebook runs a filtered wide-table DP-SGD continuation experiment and evaluates benchmark utility.\n",
        "\n",
        "It uses additive output paths only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7d36bd8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Device: `cpu`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import Adam\n",
        "from opacus import PrivacyEngine\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "ROOT = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd().resolve()\n",
        "if str(ROOT) not in sys.path:\n",
        "    sys.path.append(str(ROOT))\n",
        "\n",
        "from src.experiments.wide_dpsgd_model import DCAWidetableVAE, vae_loss\n",
        "from src.eval.decompose import decompose_wide_table\n",
        "from src.pipeline.run_benchmark import run_all\n",
        "from src.eval.compare import evaluate_all, results_to_dataframe\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "display(Markdown(f\"Device: `{device}`\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4e7772e9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Filtered table: `/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filter/wide_training_table_cov3.parquet`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Rows in filtered table: `282,315`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "FILTERED_WIDE = ROOT / 'data' / 'experiments_additive' / 'wide_filter' / 'wide_training_table_cov3.parquet'\n",
        "CHECKPOINT_PATH = ROOT / 'data' / 'models' / 'dp_vae_checkpoint.pt'\n",
        "TRANSFORMER_PATH = ROOT / 'data' / 'models' / 'transformer.pkl'\n",
        "OUT_ROOT = ROOT / 'data' / 'experiments_additive' / 'wide_filtered_dpsgd'\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "SYNTH_WIDE_PATH = OUT_ROOT / 'synth_wide_filtered_dpsgd.parquet'\n",
        "SYNTH_REPORTING_DIR = OUT_ROOT / 'reporting'\n",
        "QUERY_RESULTS_DIR = OUT_ROOT / 'query_results'\n",
        "EVAL_CSV = OUT_ROOT / 'evaluation.csv'\n",
        "\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=False)\n",
        "with open(TRANSFORMER_PATH, 'rb') as f:\n",
        "    transformer = pickle.load(f)\n",
        "\n",
        "cat_cols = checkpoint['cat_cols']\n",
        "numeric_cols = checkpoint['numeric_cols']\n",
        "cat_encoder = transformer.named_transformers_['cat']\n",
        "num_scaler = transformer.named_transformers_['num']\n",
        "\n",
        "display(Markdown(f\"Filtered table: `{FILTERED_WIDE}`\"))\n",
        "display(Markdown(f\"Rows in filtered table: `{len(pd.read_parquet(FILTERED_WIDE, columns=['guid'])):,}`\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "06524faf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Feature matrix shape: `(282315, 307)`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Finite ratio before sanitization: `1.000000`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wide = pd.read_parquet(FILTERED_WIDE)\n",
        "X = transformer.transform(wide[cat_cols + numeric_cols]).astype(np.float32)\n",
        "finite_mask = np.isfinite(X)\n",
        "finite_ratio = float(finite_mask.mean())\n",
        "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_t = torch.tensor(X, dtype=torch.float32)\n",
        "\n",
        "cat_sizes = checkpoint['model_args']['cat_sizes']\n",
        "cat_offsets = np.cumsum([0] + cat_sizes)\n",
        "cat_targets = []\n",
        "for i in range(len(cat_sizes)):\n",
        "    a, b = cat_offsets[i], cat_offsets[i + 1]\n",
        "    idx = np.argmax(X[:, a:b], axis=1).astype(np.int64)\n",
        "    cat_targets.append(torch.tensor(idx, dtype=torch.long))\n",
        "num_start = cat_offsets[-1]\n",
        "X_num = torch.tensor(X[:, num_start:], dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_t, *cat_targets, X_num)\n",
        "batch_size = 2048\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "display(Markdown(f\"Feature matrix shape: `{X.shape}`\"))\n",
        "display(Markdown(f\"Finite ratio before sanitization: `{finite_ratio:.6f}`\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dcacaafe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Probe loss before DP wrapping: `149918639145676177408.000000`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/enscribe/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  warnings.warn(\n",
            "/Users/enscribe/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
            "  warnings.warn(\n",
            "02/12/2026 16:20:58:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.\n",
            "/var/folders/_f/171dt4kn19sf0yq1gqhrb_lh0000gn/T/ipykernel_30674/2818345484.py:49: UserWarning: Full backward hook is firing when gradients are computed with respect to module outputs since no inputs require gradients. See https://docs.pytorch.org/docs/main/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook for more details.\n",
            "  loss.backward()\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Per sample gradient is not initialized. Not updated in backward pass?",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     49\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m steps += \u001b[32m1\u001b[39m\n\u001b[32m     52\u001b[39m losses.append(\u001b[38;5;28mfloat\u001b[39m(loss.detach().cpu()))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/optimizers/optimizer.py:554\u001b[39m, in \u001b[36mDPOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m    553\u001b[39m         closure()\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.original_optimizer.step()\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/optimizers/optimizer.py:537\u001b[39m, in \u001b[36mDPOptimizer.pre_step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    528\u001b[39m \u001b[33;03mPerform actions specific to ``DPOptimizer`` before calling\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03munderlying  ``optimizer.step()``\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    533\u001b[39m \u001b[33;03m        returns the loss. Optional for most optimizers.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;66;03m# The corner case when the optimizer has no trainable parameters.\u001b[39;00m\n\u001b[32m    536\u001b[39m \u001b[38;5;66;03m# Essentially the DPOptimizer act as a normal optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgrad_samples\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.grad_samples) == \u001b[32m0\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28mself\u001b[39m.clip_and_accumulate()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/optimizers/optimizer.py:343\u001b[39m, in \u001b[36mDPOptimizer.grad_samples\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    341\u001b[39m ret = []\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     ret.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_flat_grad_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/opacus/optimizers/optimizer.py:280\u001b[39m, in \u001b[36mDPOptimizer._get_flat_grad_sample\u001b[39m\u001b[34m(self, p)\u001b[39m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    277\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPer sample gradient not found. Are you using GradSampleModule?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     )\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.grad_sample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    281\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPer sample gradient is not initialized. Not updated in backward pass?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     )\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p.grad_sample, torch.Tensor):\n\u001b[32m    284\u001b[39m     ret = p.grad_sample\n",
            "\u001b[31mValueError\u001b[39m: Per sample gradient is not initialized. Not updated in backward pass?"
          ]
        }
      ],
      "source": [
        "model = DCAWidetableVAE(**checkpoint['model_args']).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer = Adam(model.parameters(), lr=2e-4)\n",
        "\n",
        "target_epsilon = 4.0\n",
        "target_delta = 1e-5\n",
        "epochs = 3\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "probe_batch = next(iter(loader))\n",
        "probe_x = probe_batch[0].to(device)\n",
        "probe_y_cats = [t.to(device) for t in probe_batch[1:1 + len(cat_sizes)]]\n",
        "probe_y_num = probe_batch[-1].to(device)\n",
        "with torch.no_grad():\n",
        "    p_cat_logits, p_num_out, p_mu, p_logvar = model(probe_x)\n",
        "    probe_loss, probe_ce, probe_mse, probe_kl = vae_loss(p_cat_logits, p_num_out, probe_y_cats, probe_y_num, p_mu, p_logvar, beta=0.1)\n",
        "if not torch.isfinite(probe_loss):\n",
        "    raise RuntimeError('Non-finite probe loss before DP wrapping. Check model stability and transformed features.')\n",
        "display(Markdown(f\"Probe loss before DP wrapping: `{float(probe_loss):.6f}`\"))\n",
        "\n",
        "privacy_engine = PrivacyEngine(accountant='rdp')\n",
        "model, optimizer, loader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=loader,\n",
        "    target_epsilon=target_epsilon,\n",
        "    target_delta=target_delta,\n",
        "    epochs=epochs,\n",
        "    max_grad_norm=max_grad_norm,\n",
        ")\n",
        "\n",
        "history = []\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    skipped = 0\n",
        "    steps = 0\n",
        "    for batch in loader:\n",
        "        x = batch[0].to(device)\n",
        "        y_cats = [t.to(device) for t in batch[1:1 + len(cat_sizes)]]\n",
        "        y_num = batch[-1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cat_logits, num_out, mu, logvar = model(x)\n",
        "        loss, ce, mse, kl = vae_loss(cat_logits, num_out, y_cats, y_num, mu, logvar, beta=0.1)\n",
        "        if not torch.isfinite(loss):\n",
        "            skipped += 1\n",
        "            continue\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        steps += 1\n",
        "        losses.append(float(loss.detach().cpu()))\n",
        "\n",
        "    eps = float('nan')\n",
        "    if steps > 0:\n",
        "        try:\n",
        "            eps = float(privacy_engine.accountant.get_epsilon(delta=target_delta))\n",
        "        except Exception:\n",
        "            eps = float('nan')\n",
        "    epoch_loss = float(np.mean(losses)) if len(losses) else float('nan')\n",
        "    history.append({'epoch': epoch + 1, 'loss': epoch_loss, 'epsilon': eps, 'skipped_batches': skipped, 'steps': steps})\n",
        "\n",
        "history_df = pd.DataFrame(history)\n",
        "display(Markdown('## Training summary'))\n",
        "display(history_df)\n",
        "if history_df['steps'].sum() == 0:\n",
        "    raise RuntimeError('No optimizer steps completed. Loss is non-finite for all batches.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6513219",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Saved synthetic wide table: `/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/synth_wide_filtered_dpsgd.parquet`"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>guid</th>\n",
              "      <th>chassistype</th>\n",
              "      <th>countryname_normalized</th>\n",
              "      <th>modelvendor_normalized</th>\n",
              "      <th>os</th>\n",
              "      <th>cpuname</th>\n",
              "      <th>cpucode</th>\n",
              "      <th>cpu_family</th>\n",
              "      <th>persona</th>\n",
              "      <th>processornumber</th>\n",
              "      <th>...</th>\n",
              "      <th>psys_rap_nrs</th>\n",
              "      <th>psys_rap_avg</th>\n",
              "      <th>pkg_c0_nrs</th>\n",
              "      <th>pkg_c0_avg</th>\n",
              "      <th>avg_freq_nrs</th>\n",
              "      <th>avg_freq_avg</th>\n",
              "      <th>temp_nrs</th>\n",
              "      <th>temp_avg</th>\n",
              "      <th>pkg_power_nrs</th>\n",
              "      <th>pkg_power_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>filtered_synth_0000000</td>\n",
              "      <td>2 in 1</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>AZW</td>\n",
              "      <td>Win Server</td>\n",
              "      <td>10th Gen i3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Atom</td>\n",
              "      <td>Casual Gamer</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>filtered_synth_0000001</td>\n",
              "      <td>2 in 1</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>AZW</td>\n",
              "      <td>Win Server</td>\n",
              "      <td>10th Gen i3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Atom</td>\n",
              "      <td>Casual Gamer</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>filtered_synth_0000002</td>\n",
              "      <td>2 in 1</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>AZW</td>\n",
              "      <td>Win Server</td>\n",
              "      <td>10th Gen i3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Atom</td>\n",
              "      <td>Casual Gamer</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>filtered_synth_0000003</td>\n",
              "      <td>2 in 1</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>AZW</td>\n",
              "      <td>Win Server</td>\n",
              "      <td>10th Gen i3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Atom</td>\n",
              "      <td>Casual Gamer</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>filtered_synth_0000004</td>\n",
              "      <td>2 in 1</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>AZW</td>\n",
              "      <td>Win Server</td>\n",
              "      <td>10th Gen i3</td>\n",
              "      <td>Other</td>\n",
              "      <td>Atom</td>\n",
              "      <td>Casual Gamer</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 69 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     guid chassistype countryname_normalized  \\\n",
              "0  filtered_synth_0000000      2 in 1              Argentina   \n",
              "1  filtered_synth_0000001      2 in 1              Argentina   \n",
              "2  filtered_synth_0000002      2 in 1              Argentina   \n",
              "3  filtered_synth_0000003      2 in 1              Argentina   \n",
              "4  filtered_synth_0000004      2 in 1              Argentina   \n",
              "\n",
              "  modelvendor_normalized          os      cpuname cpucode cpu_family  \\\n",
              "0                    AZW  Win Server  10th Gen i3   Other       Atom   \n",
              "1                    AZW  Win Server  10th Gen i3   Other       Atom   \n",
              "2                    AZW  Win Server  10th Gen i3   Other       Atom   \n",
              "3                    AZW  Win Server  10th Gen i3   Other       Atom   \n",
              "4                    AZW  Win Server  10th Gen i3   Other       Atom   \n",
              "\n",
              "        persona processornumber  ...  psys_rap_nrs  psys_rap_avg  pkg_c0_nrs  \\\n",
              "0  Casual Gamer              10  ...           NaN           NaN         NaN   \n",
              "1  Casual Gamer              10  ...           NaN           NaN         NaN   \n",
              "2  Casual Gamer              10  ...           NaN           NaN         NaN   \n",
              "3  Casual Gamer              10  ...           NaN           NaN         NaN   \n",
              "4  Casual Gamer              10  ...           NaN           NaN         NaN   \n",
              "\n",
              "   pkg_c0_avg  avg_freq_nrs  avg_freq_avg  temp_nrs  temp_avg  pkg_power_nrs  \\\n",
              "0         NaN           NaN           NaN       NaN       NaN            NaN   \n",
              "1         NaN           NaN           NaN       NaN       NaN            NaN   \n",
              "2         NaN           NaN           NaN       NaN       NaN            NaN   \n",
              "3         NaN           NaN           NaN       NaN       NaN            NaN   \n",
              "4         NaN           NaN           NaN       NaN       NaN            NaN   \n",
              "\n",
              "   pkg_power_avg  \n",
              "0            NaN  \n",
              "1            NaN  \n",
              "2            NaN  \n",
              "3            NaN  \n",
              "4            NaN  \n",
              "\n",
              "[5 rows x 69 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "N_SYNTH = len(wide)\n",
        "model.eval()\n",
        "base_model = model._module if hasattr(model, \"_module\") else model\n",
        "chunk = 8192\n",
        "cat_preds = []\n",
        "num_preds = []\n",
        "with torch.no_grad():\n",
        "    n_done = 0\n",
        "    while n_done < N_SYNTH:\n",
        "        n = min(chunk, N_SYNTH - n_done)\n",
        "        z = torch.randn(n, checkpoint['model_args']['latent_dim'], device=device)\n",
        "        cat_logits, num_out = base_model.decode(z)\n",
        "        if not torch.isfinite(num_out).all():\n",
        "            raise RuntimeError('Non-finite values in decoder numeric output. Training run is unstable.')\n",
        "        cat_idx = [torch.argmax(logits, dim=1).cpu().numpy() for logits in cat_logits]\n",
        "        num_arr = num_out.cpu().numpy()\n",
        "        cat_preds.append(cat_idx)\n",
        "        num_preds.append(num_arr)\n",
        "        n_done += n\n",
        "\n",
        "cat_arrays = [np.concatenate([chunk_cat[i] for chunk_cat in cat_preds], axis=0) for i in range(len(cat_sizes))]\n",
        "num_array = np.concatenate(num_preds, axis=0)\n",
        "\n",
        "synth_cat = {}\n",
        "for i, col in enumerate(cat_cols):\n",
        "    cats = cat_encoder.categories_[i]\n",
        "    idx = np.clip(cat_arrays[i], 0, len(cats) - 1)\n",
        "    synth_cat[col] = cats[idx]\n",
        "\n",
        "synth_num = num_scaler.inverse_transform(num_array)\n",
        "synth_wide = pd.DataFrame(synth_cat)\n",
        "for j, col in enumerate(numeric_cols):\n",
        "    synth_wide[col] = synth_num[:, j]\n",
        "synth_wide.insert(0, 'guid', [f'filtered_synth_{i:07d}' for i in range(N_SYNTH)])\n",
        "synth_wide.to_parquet(SYNTH_WIDE_PATH, index=False)\n",
        "\n",
        "display(Markdown(f\"Saved synthetic wide table: `{SYNTH_WIDE_PATH}`\"))\n",
        "display(synth_wide.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6769fd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Decomposition table row counts"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>table</th>\n",
              "      <th>rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sysinfo</td>\n",
              "      <td>282315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>network_consumption</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>memory_utilization</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>system_psys_rap_watts</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>system_pkg_C0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>system_pkg_avg_freq_mhz</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>system_pkg_temp_centigrade</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>system_hw_pkg_power</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>batt_dc_events</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>web_cat_usage</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>web_cat_pivot_duration</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>on_off_suspend_time_day</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         table    rows\n",
              "0                      sysinfo  282315\n",
              "1          network_consumption       0\n",
              "2           memory_utilization       0\n",
              "3        system_psys_rap_watts       0\n",
              "4                system_pkg_C0       0\n",
              "5      system_pkg_avg_freq_mhz       0\n",
              "6   system_pkg_temp_centigrade       0\n",
              "7          system_hw_pkg_power       0\n",
              "8               batt_dc_events       0\n",
              "9                web_cat_usage       0\n",
              "10      web_cat_pivot_duration       0\n",
              "11     on_off_suspend_time_day       0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "counts = decompose_wide_table(synth_wide, SYNTH_REPORTING_DIR)\n",
        "display(Markdown('## Decomposition table row counts'))\n",
        "display(pd.DataFrame([{'table': k, 'rows': v} for k, v in counts.items()]).sort_values('rows', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e33c64",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  FAIL battery_on_duration_cpu_family_gen: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_cpu_metadata.parquet\"\n",
            "\n",
            "LINE 1: ..., avg(duration_mins) as avg_duration_mins_on_battery from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                     ^\n",
            "  FAIL display_devices_connection_type_resolution_durations_ac_dc: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_display_devices.parquet\"\n",
            "\n",
            "LINE 1: ...(avg(duration_dc),2) as average_duration_on_dc_in_seconds from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                          ^\n",
            "  FAIL display_devices_vendors_percentage: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_display_devices.parquet\"\n",
            "\n",
            "LINE 1: ....0/ total_number_of_systems,2 )as percentage_of_systems from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                        ^\n",
            "  FAIL mods_blockers_by_osname_and_codename: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_mods_top_blocker_hist.parquet\"\n",
            "\n",
            "LINE 1: ... (select a.guid, min_ts, max_ts, os_name, os_codename, dt from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                          ^\n",
            "  FAIL on_off_mods_sleep_summary_by_cpu_marketcodename_gen: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_cpu_metadata.parquet\"\n",
            "\n",
            "LINE 1: ...ting/system_on_off_suspend_time_day.parquet') a inner join read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                      ^\n",
            "  FAIL server_exploration_1: Binder Error: Table \"b\" does not have a column named \"model_normalized\"\n",
            "\n",
            "Candidate bindings: : \"modelvendor_normalized\"\n",
            "\n",
            "LINE 1: ..._bytes, b.chassistype, b.modelvendor_normalized as vendor, b.model_normalized as model, b.ram, b.os, b.\"#ofcores\" as...\n",
            "                                                                      ^\n",
            "  FAIL top_10_applications_by_app_type_ranked_by_focal_time: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_frgnd_apps_types.parquet\"\n",
            "\n",
            "LINE 1: ... app_type order by avg(totalsecfocal_day) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                        ^\n",
            "  FAIL top_10_applications_by_app_type_ranked_by_system_count: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_frgnd_apps_types.parquet\"\n",
            "\n",
            "LINE 1: ... by app_type order by count(distinct guid) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                         ^\n",
            "  FAIL top_10_applications_by_app_type_ranked_by_total_detections: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_frgnd_apps_types.parquet\"\n",
            "\n",
            "LINE 1: ... by app_type order by sum(lines_per_day) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                       ^\n",
            "  FAIL top_mods_blocker_types_durations_by_osname_and_codename: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_mods_top_blocker_hist.parquet\"\n",
            "\n",
            "LINE 1: ..., activity_level, blocker_type, os_name, os_codename from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                     ^\n",
            "  FAIL userwait_top_10_wait_processes: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_userwait.parquet\"\n",
            "\n",
            "LINE 1: ...tion_ms/1000))/sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                      ^\n",
            "  FAIL userwait_top_10_wait_processes_wait_type_ac_dc: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_userwait.parquet\"\n",
            "\n",
            "LINE 1: ...tion_ms/1000))/sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                      ^\n",
            "  FAIL userwait_top_20_wait_processes_compare_ac_dc_unknown_durations: IO Error: No files found that match the pattern \"/Users/enscribe/Repositories/School/dsc180-q2/data/experiments_additive/wide_filtered_dpsgd/reporting/system_userwait.parquet\"\n",
            "\n",
            "LINE 1: ... / 1000)) / sum(number_of_instances) desc) as rank from read_parquet('/Users/enscribe/Repositories/School/dsc180...\n",
            "                                                                   ^\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "## Evaluation summary"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>queries_evaluated</th>\n",
              "      <th>queries_passed</th>\n",
              "      <th>pass_rate</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>evaluation_csv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/Users/enscribe/Repositories/School/dsc180-q2/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   queries_evaluated  queries_passed  pass_rate  avg_score  \\\n",
              "0                  8               0        0.0        0.0   \n",
              "\n",
              "                                      evaluation_csv  \n",
              "0  /Users/enscribe/Repositories/School/dsc180-q2/...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run_all(\n",
        "    queries_dir=ROOT / 'docs' / 'queries',\n",
        "    reporting_dir=SYNTH_REPORTING_DIR,\n",
        "    output_dir=QUERY_RESULTS_DIR,\n",
        "    skip_infeasible=True,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "eval_res = evaluate_all(ROOT / 'data' / 'results' / 'real', QUERY_RESULTS_DIR)\n",
        "eval_df = results_to_dataframe(eval_res)\n",
        "eval_df.to_csv(EVAL_CSV, index=False)\n",
        "\n",
        "ev = eval_df[eval_df['n_metrics'] > 0]\n",
        "passed = int(ev['passed'].fillna(False).sum()) if len(ev) else 0\n",
        "avg_score = float(ev['score'].mean()) if len(ev) else 0.0\n",
        "display(Markdown('## Evaluation summary'))\n",
        "display(pd.DataFrame([{\n",
        "    'queries_evaluated': len(ev),\n",
        "    'queries_passed': passed,\n",
        "    'pass_rate': passed / len(ev) if len(ev) else 0.0,\n",
        "    'avg_score': avg_score,\n",
        "    'evaluation_csv': str(EVAL_CSV),\n",
        "}]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d123e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Delta vs wide-table baseline"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline_passed</th>\n",
              "      <th>new_passed</th>\n",
              "      <th>delta_passed</th>\n",
              "      <th>baseline_avg_score</th>\n",
              "      <th>new_avg_score</th>\n",
              "      <th>delta_avg_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.258065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.258065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   baseline_passed  new_passed  delta_passed  baseline_avg_score  \\\n",
              "0                1           0            -1            0.258065   \n",
              "\n",
              "   new_avg_score  delta_avg_score  \n",
              "0            0.0        -0.258065  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "baseline = pd.read_csv(ROOT / 'data' / 'results' / 'evaluation_widetable.csv')\n",
        "b = baseline[baseline['n_metrics'] > 0]\n",
        "n = pd.read_csv(EVAL_CSV)\n",
        "n = n[n['n_metrics'] > 0]\n",
        "display(Markdown('## Delta vs wide-table baseline'))\n",
        "display(pd.DataFrame([{\n",
        "    'baseline_passed': int(b['passed'].fillna(False).sum()),\n",
        "    'new_passed': int(n['passed'].fillna(False).sum()),\n",
        "    'delta_passed': int(n['passed'].fillna(False).sum()) - int(b['passed'].fillna(False).sum()),\n",
        "    'baseline_avg_score': float(b['score'].mean()) if len(b) else 0.0,\n",
        "    'new_avg_score': float(n['score'].mean()) if len(n) else 0.0,\n",
        "    'delta_avg_score': (float(n['score'].mean()) - float(b['score'].mean())) if len(b) and len(n) else 0.0,\n",
        "}]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
