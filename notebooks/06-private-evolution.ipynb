{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06: Private Evolution for Tabular Data\n",
    "\n",
    "This notebook implements Private Evolution (PE) adapted for the DCA telemetry wide table, following Lin et al. (2024) and Swanberg et al. (2025). Instead of training a generative model with DP-SGD, PE uses black-box API access to a foundation model (GPT-5 nano) and a DP nearest-neighbor histogram to iteratively select synthetic candidates that best approximate the real data distribution.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Load the wide training table (from notebook 05)\n",
    "2. Configure PE parameters and privacy budget\n",
    "3. Run PE (RANDOM_API -> DP histogram -> selection -> VARIATION_API)\n",
    "4. Decompose synthetic wide table into reporting tables\n",
    "5. Run benchmark queries and compare with ground truth and DP-SGD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(Path(\"../.env\"))\n",
    "\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "REPORTING = Path(\"../data/reporting\")\n",
    "QUERIES_DIR = Path(\"../docs/queries\")\n",
    "REAL_RESULTS = Path(\"../data/results/real\")\n",
    "PE_REPORTING = Path(\"../data/reporting/pe\")\n",
    "PE_RESULTS = Path(\"../data/results/pe\")\n",
    "MODEL = \"gpt-5-nano\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load the wide training table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Wide table: 1,000,000 rows x 69 columns\n",
       "\n",
       "Categorical: 9 columns, Numeric: 59 columns"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wide = pd.read_parquet(REPORTING / \"wide_training_table.parquet\")\n",
    "\n",
    "cat_cols = [\"chassistype\", \"countryname_normalized\", \"modelvendor_normalized\",\n",
    "            \"os\", \"cpuname\", \"cpucode\", \"cpu_family\", \"persona\", \"processornumber\"]\n",
    "numeric_cols = [c for c in wide.columns if c != \"guid\" and c not in cat_cols]\n",
    "\n",
    "display(Markdown(\n",
    "    f\"Wide table: {len(wide):,} rows x {len(wide.columns)} columns\\n\\n\"\n",
    "    f\"Categorical: {len(cat_cols)} columns, Numeric: {len(numeric_cols)} columns\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Configure PE and privacy budget\n",
    "\n",
    "Following Swanberg et al. (2025), we use T=1 iteration as the primary setting (their finding that T=1 is optimal for tabular PE). We match the DP-SGD privacy budget: epsilon=4.0, delta=1e-5.\n",
    "\n",
    "The noise multiplier sigma is calibrated via the analytic Gaussian mechanism (Balle and Wang, 2018) with adaptive composition (Dong et al., 2019): T iterations with noise sigma each compose to a single Gaussian mechanism with effective sensitivity sqrt(T)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "PE configuration:\n",
       "\n",
       "- Model: `gpt-5-nano`\n",
       "- N_synth: 50,000\n",
       "- T (iterations): 1\n",
       "- L (variations per candidate + 1): 3\n",
       "- Target epsilon: 4.0, delta: 1e-05\n",
       "- Calibrated sigma: 1.0812\n",
       "- Initial population: 150,000 (N_synth x L)\n",
       "- Privacy guarantee: (epsilon=4.0, delta=1e-05)-DP via analytic Gaussian mechanism"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.pe.privacy import calibrate_sigma, compute_epsilon\n",
    "\n",
    "N_SYNTH = 50000\n",
    "T = 1\n",
    "L = 3\n",
    "EPSILON = 4.0\n",
    "DELTA = 1e-5\n",
    "MODEL = \"gpt-5-nano\"\n",
    "\n",
    "sigma = calibrate_sigma(EPSILON, DELTA, T)\n",
    "\n",
    "display(Markdown(\n",
    "    f\"PE configuration:\\n\\n\"\n",
    "    f\"- Model: `{MODEL}`\\n\"\n",
    "    f\"- N_synth: {N_SYNTH:,}\\n\"\n",
    "    f\"- T (iterations): {T}\\n\"\n",
    "    f\"- L (variations per candidate + 1): {L}\\n\"\n",
    "    f\"- Target epsilon: {EPSILON}, delta: {DELTA}\\n\"\n",
    "    f\"- Calibrated sigma: {sigma:.4f}\\n\"\n",
    "    f\"- Initial population: {N_SYNTH * L:,} (N_synth x L)\\n\"\n",
    "    f\"- Privacy guarantee: (epsilon={EPSILON}, delta={DELTA})-DP via analytic Gaussian mechanism\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Run Private Evolution\n",
    "\n",
    "The PE loop:\n",
    "1. RANDOM_API generates 150,000 initial candidates (N_synth x L = 50K x 3)\n",
    "2. Each of the 1M real records votes for its nearest synthetic candidate under the workload-aware distance\n",
    "3. Gaussian noise (sigma) is added to the histogram to ensure DP\n",
    "4. Top 50,000 candidates are selected by rank\n",
    "\n",
    "With T=1, there is no VARIATION_API call (selection is the final step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE config: N_synth=50000, T=1, L=3, epsilon=4.0, delta=1e-05, sigma=1.0812, voting_records=1,000,000, mode=Batch API (50% cheaper)\n",
      "\n",
      "--- Generating initial population (N=150000) ---\n",
      "RANDOM_API_BATCH: 150000 records (18750 calls across 24 batch(es), 25% buffer)\n",
      "  24 sequential chunk(s) of up to 800 requests\n",
      "  RANDOM chunk 1/24: loaded 7893 cached records\n",
      "  RANDOM chunk 2/24: loaded 7886 cached records\n",
      "  RANDOM chunk 3/24: loaded 7894 cached records\n",
      "  RANDOM chunk 4/24: loaded 7979 cached records\n",
      "  RANDOM chunk 5/24: resuming batch batch_698d9d3ccdfc81909f0ff84f6cf51f4d\n",
      "  RANDOM chunk 5/24: 780/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 5/24: 780/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 5/24: 780/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 5/24: 780/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 5/24: 780/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 5/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 5/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 5/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 5/24: 7867 records saved\n",
      "  RANDOM chunk 6/24: batch batch_698da032ddc88190b96c0b348b8f414a submitted (0 requests)\n",
      "  RANDOM chunk 6/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 6/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 22/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 37/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 112/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 152/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 212/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 263/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 289/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 375/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 402/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 455/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 470/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 529/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 543/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 543/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 555/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 573/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 573/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 592/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 592/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 614/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 614/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 662/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 685/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 685/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 711/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 739/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 769/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 799/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 6/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 6/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 6/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 6/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 6/24: 7869 records saved\n",
      "  RANDOM chunk 7/24: batch batch_698da6b0b4ec81909aa9461320e32be3 submitted (0 requests)\n",
      "  RANDOM chunk 7/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 7/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 45/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 168/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 616/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 796/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 7/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 7/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 7/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 7/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 7/24: 7888 records saved\n",
      "  RANDOM chunk 8/24: batch batch_698da81e52c08190a67c250e70796f21 submitted (0 requests)\n",
      "  RANDOM chunk 8/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 8/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 9/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 46/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 98/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 298/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 776/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 795/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 8/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 8/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 8/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 8/24: 7930 records saved\n",
      "  RANDOM chunk 9/24: batch batch_698dac22eedc8190bbfd8055c1eb15f8 submitted (0 requests)\n",
      "  RANDOM chunk 9/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 9/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 20/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 108/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 310/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 548/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 710/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 723/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 744/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 744/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 744/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 744/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 744/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 766/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 766/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 766/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 766/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 782/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 9/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 9/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 9/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 9/24: 7952 records saved\n",
      "  RANDOM chunk 10/24: batch batch_698dae81dce4819085635b65a8886f9e submitted (0 requests)\n",
      "  RANDOM chunk 10/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 10/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 86/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 450/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 525/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 585/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 773/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 10/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 10/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 10/24: 800/800 done, 0 failed [finalizing]\n",
      "  RANDOM chunk 10/24: 800/800 done, 0 failed [completed]\n",
      "  Chunk 10/24: 7856 records saved\n",
      "  RANDOM chunk 11/24: batch batch_698db2e79118819089e6cf8652e96913 submitted (0 requests)\n",
      "  RANDOM chunk 11/24: 0/0 done, 0 failed [validating]\n",
      "  RANDOM chunk 11/24: 0/800 done, 0 failed [in_progress]\n",
      "  RANDOM chunk 11/24: 0/800 done, 0 failed [in_progress]\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectTimeout\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:156\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mstart_tls\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     stream = \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:154\u001b[39m, in \u001b[36mSyncStream.start_tls\u001b[39m\u001b[34m(self, ssl_context, server_hostname, timeout)\u001b[39m\n\u001b[32m    150\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    151\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    152\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    153\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectTimeout\u001b[39m: _ssl.c:993: The handshake operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectTimeout\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/openai/_base_client.py:1005\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectTimeout\u001b[39m: _ssl.c:993: The handshake operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPITimeoutError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m WORK_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m CHECKPOINT_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m synth_wide, pe_history = \u001b[38;5;28;01mawait\u001b[39;00m private_evolution(\n\u001b[32m     19\u001b[39m     real_df=wide,\n\u001b[32m     20\u001b[39m     api=api,\n\u001b[32m     21\u001b[39m     n_synth=N_SYNTH,\n\u001b[32m     22\u001b[39m     T=T,\n\u001b[32m     23\u001b[39m     L=L,\n\u001b[32m     24\u001b[39m     epsilon=EPSILON,\n\u001b[32m     25\u001b[39m     delta=DELTA,\n\u001b[32m     26\u001b[39m     real_chunk=\u001b[32m5000\u001b[39m,\n\u001b[32m     27\u001b[39m     synth_chunk=\u001b[32m10000\u001b[39m,\n\u001b[32m     28\u001b[39m     batch_size=\u001b[32m10\u001b[39m,\n\u001b[32m     29\u001b[39m     variation_batch_size=\u001b[32m5\u001b[39m,\n\u001b[32m     30\u001b[39m     use_batch=USE_BATCH,\n\u001b[32m     31\u001b[39m     work_dir=WORK_DIR,\n\u001b[32m     32\u001b[39m     checkpoint_dir=CHECKPOINT_DIR,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m display(Markdown(\n\u001b[32m     36\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPE complete:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Synthetic records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(synth_wide)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mBatch API (50\u001b[39m\u001b[38;5;132;01m% c\u001b[39;00m\u001b[33mheaper)\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mUSE_BATCH\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRealtime API\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/src/pe/histogram.py:167\u001b[39m, in \u001b[36mprivate_evolution\u001b[39m\u001b[34m(real_df, api, n_synth, T, L, epsilon, delta, real_chunk, synth_chunk, batch_size, variation_batch_size, real_subsample, use_batch, work_dir, checkpoint_dir)\u001b[39m\n\u001b[32m    165\u001b[39m t0 = time.time()\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_batch:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     S_t = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom_api_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_synth\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwork_dir\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    171\u001b[39m     S_t = \u001b[38;5;28;01mawait\u001b[39;00m api.random_api(n_synth * L, batch_size=batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/src/pe/api.py:544\u001b[39m, in \u001b[36mPEApi.random_api_batch\u001b[39m\u001b[34m(self, n_records, batch_size, work_dir)\u001b[39m\n\u001b[32m    536\u001b[39m prompts = [\n\u001b[32m    537\u001b[39m     _build_random_prompt(\u001b[38;5;28mself\u001b[39m.schema_desc, batch_size)\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls)\n\u001b[32m    539\u001b[39m ]\n\u001b[32m    540\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    541\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRANDOM_API_BATCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_records\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_calls\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m calls across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m batch(es), 25% buffer)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m all_chunk_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_multi_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrandom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    545\u001b[39m all_records = [r \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m all_chunk_results \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m chunk]\n\u001b[32m    546\u001b[39m raw = \u001b[38;5;28mlen\u001b[39m(all_records)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/src/pe/api.py:508\u001b[39m, in \u001b[36mPEApi._run_multi_batch\u001b[39m\u001b[34m(self, prompts, tag, work_dir)\u001b[39m\n\u001b[32m    503\u001b[39m     batch_id = \u001b[38;5;28mself\u001b[39m._submit_batch(\n\u001b[32m    504\u001b[39m         jsonl_path, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_batch_state(ci, batch_id, tag, work_dir)\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtag\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m chunk \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mci\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_chunks\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    509\u001b[39m chunk_records: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] = []\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m status.status == \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m status.output_file_id:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/src/pe/api.py:397\u001b[39m, in \u001b[36mPEApi._poll_batch\u001b[39m\u001b[34m(self, batch_id, desc, poll_interval)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll_batch\u001b[39m(\n\u001b[32m    394\u001b[39m     \u001b[38;5;28mself\u001b[39m, batch_id: \u001b[38;5;28mstr\u001b[39m, desc: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, poll_interval: \u001b[38;5;28mint\u001b[39m = \u001b[32m30\u001b[39m\n\u001b[32m    395\u001b[39m ) -> Any:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m         status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msync_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m         rc = status.request_counts\n\u001b[32m    399\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m rc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/openai/resources/batches.py:152\u001b[39m, in \u001b[36mBatches.retrieve\u001b[39m\u001b[34m(self, batch_id, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_id:\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a non-empty value for `batch_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/batches/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbatch_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/openai/_base_client.py:1228\u001b[39m, in \u001b[36mSyncAPIClient.get\u001b[39m\u001b[34m(self, path, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mget\u001b[39m\u001b[33m\"\u001b[39m, url=path, **options)\n\u001b[32m   1226\u001b[39m \u001b[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001b[39;00m\n\u001b[32m   1227\u001b[39m \u001b[38;5;66;03m# it understands the type variables\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1228\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/School/dsc180-q2/.venv/lib/python3.12/site-packages/openai/_base_client.py:1023\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1022\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising timeout error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1025\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered Exception\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAPITimeoutError\u001b[39m: Request timed out."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.pe.api, src.pe.distance, src.pe.privacy, src.pe.histogram\n",
    "importlib.reload(src.pe.api)\n",
    "importlib.reload(src.pe.distance)\n",
    "importlib.reload(src.pe.privacy)\n",
    "importlib.reload(src.pe.histogram)\n",
    "from src.pe.histogram import private_evolution\n",
    "from src.pe.api import PEApi\n",
    "\n",
    "api = PEApi(wide, model=MODEL, max_concurrent=50)\n",
    "\n",
    "USE_BATCH = True\n",
    "WORK_DIR = Path(\"../data/batch_jobs\")\n",
    "CHECKPOINT_DIR = Path(\"../data/pe_checkpoints\")\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "synth_wide, pe_history = await private_evolution(\n",
    "    real_df=wide,\n",
    "    api=api,\n",
    "    n_synth=N_SYNTH,\n",
    "    T=T,\n",
    "    L=L,\n",
    "    epsilon=EPSILON,\n",
    "    delta=DELTA,\n",
    "    real_chunk=5000,\n",
    "    synth_chunk=10000,\n",
    "    batch_size=10,\n",
    "    variation_batch_size=5,\n",
    "    use_batch=USE_BATCH,\n",
    "    work_dir=WORK_DIR,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    ")\n",
    "\n",
    "display(Markdown(\n",
    "    f\"PE complete:\\n\\n\"\n",
    "    f\"- Synthetic records: {len(synth_wide):,}\\n\"\n",
    "    f\"- Total time: {pe_history['total_time']:.1f}s\\n\"\n",
    "    f\"- Actual epsilon: {pe_history['actual_epsilon']:.4f}\\n\"\n",
    "    f\"- Sigma: {pe_history['sigma']:.4f}\\n\"\n",
    "    f\"- Mode: {'Batch API (50% cheaper)' if USE_BATCH else 'Realtime API'}\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_wide.to_parquet(REPORTING / \"pe_wide_table.parquet\", index=False)\n",
    "\n",
    "display(Markdown(f\"Saved PE synthetic wide table: {len(synth_wide):,} rows x {len(synth_wide.columns)} columns\"))\n",
    "display(synth_wide.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect sparsity patterns\n",
    "\n",
    "A key question: does the LLM generate realistic sparsity patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_rows = []\n",
    "for c in numeric_cols:\n",
    "    real_nz = (wide[c] > 0).mean() * 100\n",
    "    synth_nz = (synth_wide[c] > 0).mean() * 100 if c in synth_wide.columns else 0\n",
    "    sparsity_rows.append({\"column\": c, \"real_nonzero_pct\": round(real_nz, 1), \"synth_nonzero_pct\": round(synth_nz, 1)})\n",
    "\n",
    "sparsity_df = pd.DataFrame(sparsity_rows)\n",
    "display(Markdown(\"Nonzero percentage comparison (real vs PE synthetic):\"))\n",
    "display(sparsity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Decompose into reporting tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.decompose import decompose_wide_table\n",
    "\n",
    "counts = decompose_wide_table(synth_wide, PE_REPORTING)\n",
    "\n",
    "rows = \"\\n\".join(f\"| {t} | {c:,} |\" for t, c in counts.items())\n",
    "display(Markdown(f\"Decomposed into {len(counts)} synthetic reporting tables:\\n\\n| Table | Rows |\\n|---|---|\\n{rows}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Benchmark evaluation\n",
    "\n",
    "Run the same 8 benchmark queries evaluated for DP-SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.benchmark import run_benchmark\n",
    "\n",
    "eval_queries = [\n",
    "    \"avg_platform_power_c0_freq_temp_by_chassis\",\n",
    "    \"Xeon_network_consumption\",\n",
    "    \"pkg_power_by_country\",\n",
    "    \"ram_utilization_histogram\",\n",
    "    \"battery_power_on_geographic_summary\",\n",
    "    \"persona_web_cat_usage_analysis\",\n",
    "    \"popular_browsers_by_count_usage_percentage\",\n",
    "    \"most_popular_browser_in_each_country_by_system_count\",\n",
    "]\n",
    "\n",
    "pe_results = run_benchmark(eval_queries, QUERIES_DIR, PE_REPORTING, PE_RESULTS)\n",
    "\n",
    "display(Markdown(f\"{len(pe_results)}/{len(eval_queries)} queries executed on PE synthetic data.\"))\n",
    "for name, df in pe_results.items():\n",
    "    display(Markdown(f\"### `{name}` ({len(df)} rows)\"))\n",
    "    display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Comparison with ground truth and DP-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPSGD_RESULTS = Path(\"../data/results/synthetic\")\n",
    "\n",
    "comparison_rows = []\n",
    "for name in eval_queries:\n",
    "    real_path = REAL_RESULTS / f\"{name}.csv\"\n",
    "    dpsgd_path = DPSGD_RESULTS / f\"{name}.csv\"\n",
    "    pe_path = PE_RESULTS / f\"{name}.csv\"\n",
    "\n",
    "    if not real_path.exists():\n",
    "        continue\n",
    "    real_df = pd.read_csv(real_path)\n",
    "\n",
    "    for col in real_df.select_dtypes(include=[np.number]).columns:\n",
    "        real_mean = real_df[col].mean()\n",
    "        if abs(real_mean) < 1e-10:\n",
    "            continue\n",
    "\n",
    "        row = {\"query\": name.replace(\"_\", \" \"), \"column\": col, \"real_mean\": real_mean}\n",
    "\n",
    "        if dpsgd_path.exists():\n",
    "            dpsgd_df = pd.read_csv(dpsgd_path)\n",
    "            if col in dpsgd_df.columns:\n",
    "                dpsgd_mean = dpsgd_df[col].mean()\n",
    "                row[\"dpsgd_mean\"] = dpsgd_mean\n",
    "                row[\"dpsgd_rel_error\"] = abs(real_mean - dpsgd_mean) / abs(real_mean)\n",
    "\n",
    "        if pe_path.exists():\n",
    "            pe_df = pd.read_csv(pe_path)\n",
    "            if col in pe_df.columns:\n",
    "                pe_mean = pe_df[col].mean()\n",
    "                row[\"pe_mean\"] = pe_mean\n",
    "                row[\"pe_rel_error\"] = abs(real_mean - pe_mean) / abs(real_mean)\n",
    "\n",
    "        comparison_rows.append(row)\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_rows)\n",
    "display(Markdown(\"Column-level mean comparison (real vs DP-SGD vs PE):\"))\n",
    "display(comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_query = \"most_popular_browser_in_each_country_by_system_count\"\n",
    "real_browsers = pd.read_csv(REAL_RESULTS / f\"{browser_query}.csv\")\n",
    "\n",
    "pe_browsers_path = PE_RESULTS / f\"{browser_query}.csv\"\n",
    "if pe_browsers_path.exists():\n",
    "    pe_browsers = pd.read_csv(pe_browsers_path)\n",
    "    merged = real_browsers.merge(pe_browsers, on=\"country\", suffixes=(\"_real\", \"_pe\"), how=\"inner\")\n",
    "    matches = (merged[\"browser_real\"] == merged[\"browser_pe\"]).sum()\n",
    "    total = len(merged)\n",
    "    display(Markdown(\n",
    "        f\"Browser ranking accuracy (PE): {matches}/{total} countries correct \"\n",
    "        f\"({100*matches/total:.0f}%)\"\n",
    "    ))\n",
    "\n",
    "    dpsgd_browsers_path = DPSGD_RESULTS / f\"{browser_query}.csv\"\n",
    "    if dpsgd_browsers_path.exists():\n",
    "        dpsgd_browsers = pd.read_csv(dpsgd_browsers_path)\n",
    "        merged_dpsgd = real_browsers.merge(dpsgd_browsers, on=\"country\", suffixes=(\"_real\", \"_dpsgd\"), how=\"inner\")\n",
    "        dpsgd_matches = (merged_dpsgd[\"browser_real\"] == merged_dpsgd[\"browser_dpsgd\"]).sum()\n",
    "        dpsgd_total = len(merged_dpsgd)\n",
    "        display(Markdown(\n",
    "            f\"Browser ranking accuracy (DP-SGD): {dpsgd_matches}/{dpsgd_total} countries correct \"\n",
    "            f\"({100*dpsgd_matches/dpsgd_total:.0f}%)\"\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_lines = [\n",
    "    \"| | DP-SGD (VAE) | Private Evolution |\",\n",
    "    \"|---|---|---|\",\n",
    "    f\"| Model | DP-VAE (505K params) | GPT-5 nano (API) |\",\n",
    "    f\"| Privacy | (3.996, 1e-5)-DP | ({pe_history['actual_epsilon']:.3f}, 1e-5)-DP |\",\n",
    "    f\"| Synthetic records | 1,000,000 | {len(synth_wide):,} |\",\n",
    "    f\"| Training/generation time | 360 min (CPU) | {pe_history['total_time']:.0f}s |\",\n",
    "    f\"| Iterations | 20 epochs | {T} PE iteration(s) |\",\n",
    "]\n",
    "\n",
    "display(Markdown(\"\\n\".join(summary_lines)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
