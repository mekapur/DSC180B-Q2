<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Results | Training-based vs Training-free Differential Privacy</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body data-page="results">
  <div id="siteHeader"></div>

  <main>
    <section class="section">
      <h1>Results</h1>
      <p class="lead">
        Quantitative evaluation of all four methods across 21 benchmark SQL queries.
      </p>
    </section>

    <!-- OVERALL SUMMARY -->
    <section class="section">
      <h2>Overall Pass Rates</h2>
      <div class="results-summary">
        <div class="score-card">
          <h3>Per-Table DP-SGD</h3>
          <p class="score">6/21</p>
          <p class="small">Queries passed</p>
        </div>
        <div class="score-card">
          <h3>MST (Marginal)</h3>
          <p class="score">6/21</p>
          <p class="small">Queries passed</p>
        </div>
        <div class="score-card">
          <h3>Wide-Table DP-VAE</h3>
          <p class="score">1/8</p>
          <p class="small">Evaluated subset</p>
        </div>
        <div class="score-card">
          <h3>Private Evolution</h3>
          <p class="score">2/8</p>
          <p class="small">Evaluated subset</p>
        </div>
      </div>
    </section>

    <!-- KEY INSIGHTS -->
    <section class="section">
      <h2>Key Insights</h2>
      <h3>What Worked</h3>
      <ul class="bullets">
        <li><strong>Simple distributions:</strong> Histogram and category percentage queries largely passed. TV distance was often below threshold.</li>
        <li><strong>Independent features:</strong> When attributes are uncorrelated, per-table DP-SGD preserved fidelity well.</li>
        <li><strong>MST on structured data:</strong> Marginal-based synthesis excelled at queries with high-cardinality group-by keys where relationships could be captured.</li>
      </ul>

      <h3>What Failed</h3>
      <ul class="bullets">
        <li><strong>Join-heavy aggregates:</strong> Queries requiring cross-table relationships (e.g., "avg power by CPU type and location") failed across all methods.</li>
        <li><strong>Wide-table collapse:</strong> DP-VAE on wide-table representation suffered from sparsity: zero-inflation destroyed continuous distributions.</li>
        <li><strong>Category mismatch (PE):</strong> Private Evolution could not synthesize categories or values unseen in the LLM's training data.</li>
      </ul>

      <h3>Trade-offs</h3>
      <ul class="bullets">
        <li><strong>Per-table vs wide-table:</strong> Per-table improved within-table fidelity but broke foreign-key relationships. Wide-table preserved structure but sacrificed individual feature quality.</li>
        <li><strong>Training vs training-free:</strong> Training-based methods (DP-SGD) required careful hyperparameter tuning. Training-free (PE) was faster but limited by LLM coverage.</li>
      </ul>
    </section>

    <!-- QUERY-BY-QUERY BREAKDOWN -->
    <section class="section">
      <h2>Query Categories & Performance</h2>

      <h3>Aggregate Queries (join-heavy, complex grouping)</h3>
      <p>
        Queries that require joining tables and then aggregating metrics. Examples: "avg power by country",
        "network bytes by CPU family".
      </p>
      <ul class="bullets">
        <li><strong>Passed:</strong> Queries with simple one-table groups (e.g., "personas by web category usage").</li>
        <li><strong>Failed:</strong> Queries with cross-table grouping (e.g., "by chassis, CPU frequency, temperature").</li>
        <li><strong>Best method:</strong> Per-table DP-SGD and MST tied, each passing 4-5 aggregate queries.</li>
      </ul>

      <h3>Distribution Queries (histograms, percentages)</h3>
      <p>
        Categorical or binned distributions. Examples: "browser usage percentages", "RAM utilization histogram".
      </p>
      <ul class="bullets">
        <li><strong>Passed:</strong> Simple 3-5 category distributions (browser, display vendor).</li>
        <li><strong>Failed:</strong> Highly granular histograms (RAM utilization across 70 bins).</li>
        <li><strong>Best method:</strong> MST and Per-table DP-SGD both passed ~2-3 distribution queries.</li>
      </ul>

      <h3>Ranking Queries (top-K items)</h3>
      <p>
        Identify top items by count, focal time, or detection frequency. Examples: "top 10 applications by system count".
      </p>
      <ul class="bullets">
        <li><strong>Passed:</strong> Queries where top items in synthetic data overlapped with real top items.</li>
        <li><strong>Failed:</strong> Queries where LLM or DP noise shifted ranking significantly.</li>
        <li><strong>Best method:</strong> MST passed more ranking queries due to Jaccard overlap on top items.</li>
      </ul>

      <h3>Row-Level Queries</h3>
      <p>
        Summary statistics computed on individual records. Examples: "row count", "vendor distribution", "mean values".
      </p>
      <ul class="bullets">
        <li><strong>Passed:</strong> Simple count and distribution metrics.</li>
        <li><strong>Failed:</strong> Aggregate metrics on numerical features (network bytes, power consumption).</li>
        <li><strong>Best method:</strong> Per-table DP-SGD, due to better calibration of individual columns.</li>
      </ul>
    </section>

    <!-- FAILURE MODES IN DETAIL -->
    <section class="section">
      <h2>Failure Modes</h2>

      <h3>1. Sparsity and Zero-Inflation (Wide-Table DP-VAE)</h3>
      <p>
        When all tables are flattened into one wide table, most columns are null (sparse). The VAE encodes
        this as zero-heavy distributions, collapsing numeric ranges and losing granularity.
      </p>
      <p><strong>Impact:</strong> Continuous metrics (power, bytes, duration) became nearly constant or clustered at low values.</p>

      <h3>2. Per-Table Independence (Per-Table DP-SGD, MST)</h3>
      <p>
        Generating each table independently destroys foreign-key relationships. A CPU record in the synthetic
        data may reference a non-existent system or vice versa.
      </p>
      <p><strong>Impact:</strong> Queries relying on multi-table joins had low group coverage (Jaccard < 0.5) or inflated relative errors.</p>

      <h3>3. Category Support Mismatch (Private Evolution)</h3>
      <p>
        The LLM was trained on limited data and does not know all device vendors, OS versions, or browser variants in the real dataset.
      </p>
      <p><strong>Impact:</strong> Geographic queries, rare OS names, and uncommon applications were not synthesized, causing 0% group coverage.</p>

      <h3>4. DP Noise Masking Signal (All Methods)</h3>
      <p>
        Differential privacy noise must be large enough for privacy, but too much noise washes out subtle
        relationships (e.g., correlation between CPU frequency and power).
      </p>
      <p><strong>Impact:</strong> Queries on weak correlations or rare subgroups failed even when data was otherwise accurate.</p>
    </section>

    <!-- METHODOLOGY DETAILS -->
    <section class="section">
      <h2>Evaluation Methodology</h2>
      <h3>Privacy Budget</h3>
      <p>
        All methods were configured with epsilon = 1.0 (moderate privacy). Sensitivity to epsilon varies:
        lower epsilon improves privacy but degrades utility, especially for complex queries.
      </p>

      <h3>Data Split</h3>
      <p>
        Training data: 80% of real records. Test data: 20% held-out queries evaluated on synthetic data.
      </p>

      <h3>Metrics Thresholds</h3>
      <table style="width: 100%; border-collapse: collapse; margin-top: 16px;">
        <tr style="border-bottom: 1px solid var(--border);">
          <th style="text-align: left; padding: 8px;">Metric</th>
          <th style="text-align: left; padding: 8px;">Type</th>
          <th style="text-align: left; padding: 8px;">Pass Threshold</th>
        </tr>
        <tr style="border-bottom: 1px solid var(--border);">
          <td style="padding: 8px;">Relative Error</td>
          <td style="padding: 8px;">Aggregate</td>
          <td style="padding: 8px;">≤ 0.3 (median)</td>
        </tr>
        <tr style="border-bottom: 1px solid var(--border);">
          <td style="padding: 8px;">Total Variation</td>
          <td style="padding: 8px;">Distribution</td>
          <td style="padding: 8px;">≤ 0.15</td>
        </tr>
        <tr style="border-bottom: 1px solid var(--border);">
          <td style="padding: 8px;">Jaccard Similarity</td>
          <td style="padding: 8px;">Group Coverage</td>
          <td style="padding: 8px;">≥ 0.5</td>
        </tr>
        <tr style="border-bottom: 1px solid var(--border);">
          <td style="padding: 8px;">Spearman Rho</td>
          <td style="padding: 8px;">Ranking</td>
          <td style="padding: 8px;">≥ 0.7</td>
        </tr>
      </table>
    </section>

    <!-- RECOMMENDATIONS -->
    <section class="section">
      <h2>Recommendations</h2>
      <ul class="bullets">
        <li><strong>For simple queries:</strong> MST and per-table DP-SGD are equally good. MST is faster; per-table DP-SGD has lower privacy overhead.</li>
        <li><strong>For cross-table queries:</strong> Neither method is sufficient. Investigate relational DP synthesis (e.g., local DP on joins).</li>
        <li><strong>For workload-specific synthesis:</strong> Private Evolution shows promise but needs expanded knowledge base and better query guidance.</li>
        <li><strong>Hybrid approach:</strong> Route different queries to different methods: simple aggregates to MST, row-level to DP-SGD, complex joins to relational DP.</li>
      </ul>
    </section>
  </main>

  <div id="siteFooter"></div>

  <script src="app.js"></script>
</body>
</html>
