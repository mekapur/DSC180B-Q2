<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Methods | Training-based vs Training-free Differential Privacy</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body data-page="methods">
  <div id="siteHeader"></div>

  <main>
    <section class="section">
      <h1>Methods</h1>
      <p class="lead">
        We compared two main approaches for generating differentially private synthetic data on device telemetry.
      </p>
    </section>

    <!-- WHAT IS DIFFERENTIAL PRIVACY -->
    <section class="section">
      <h2>What is Differential Privacy?</h2>
      <p>
        Differential privacy is a mathematical framework that quantifies privacy loss. It adds carefully calibrated
        randomness to an algorithm so that its output does not reveal whether any single record (person or device) is
        in the dataset.
      </p>
      <div class="callout">
        <p>
          <strong>Simple explanation:</strong> Imagine a census. Differential privacy ensures that the published
          summary statistics would be nearly identical whether or not your specific data was included.
        </p>
      </div>
      <p>
        This is measured by a parameter epsilon (ε). Smaller epsilon means stronger privacy but potentially lower utility.
      </p>
    </section>

    <!-- APPROACH 1: TRAINING-BASED -->
    <section class="section">
      <h2>Approach 1: Training-Based (DP-SGD + VAE)</h2>
      <h3>Motivation</h3>
      <p>
        Train a generative model (Variational Autoencoder) using differentially private stochastic gradient descent.
        The model learns a compressed representation of the data, then generates new samples that mimic real distributions.
      </p>
      <h3>How it works</h3>
      <ul class="bullets">
        <li>Data is represented as a wide table (all columns combined) to preserve cross-table relationships.</li>
        <li>A VAE encoder learns latent representations; the decoder generates synthetic records.</li>
        <li>Training uses DP-SGD: gradients are clipped and noise is added at each step.</li>
        <li>After training, generate unlimited synthetic records from the learned model.</li>
      </ul>
      <h3>Advantages</h3>
      <ul class="bullets">
        <li>Can capture complex distributions and multi-table relationships.</li>
        <li>One training pass; then infinitely scalable synthesis.</li>
      </ul>
      <h3>Challenges</h3>
      <ul class="bullets">
        <li>Wide table representation: extreme sparsity and zero-inflation collapse numeric ranges.</li>
        <li>Prone to mode collapse: skipped categories or degenerate outputs.</li>
      </ul>
    </section>

    <!-- APPROACH 2: TRAINING-FREE -->
    <section class="section">
      <h2>Approach 2: Training-Free (Private Evolution)</h2>
      <h3>Motivation</h3>
      <p>
        Skip training: use a language model to generate candidate records, then use differential privacy
        to select the candidates that best match real data.
      </p>
      <h3>How it works</h3>
      <ul class="bullets">
        <li>An LLM generates many candidate synthetic records (e.g., 10,000s).</li>
        <li>For each candidate, measure distance to real data under a workload-aware metric.</li>
        <li>Use exponential mechanism (a DP algorithm) to select top candidates biased toward better fidelity.</li>
        <li>Return selected records as synthetic data.</li>
      </ul>
      <h3>Advantages</h3>
      <ul class="bullets">
        <li>No training needed; fast turnaround.</li>
        <li>Can be guided by a workload (optimize for specific queries).</li>
      </ul>
      <h3>Challenges</h3>
      <ul class="bullets">
        <li>Limited by LLM's training data: category support may not match real distributions.</li>
        <li>DP noise reduces diversity in selection, potentially limiting realism.</li>
      </ul>
    </section>

    <!-- BASELINES -->
    <section class="section">
      <h2>Baselines</h2>
      <h3>Per-Table DP-SGD</h3>
      <p>
        Train a separate generative model for each table independently. Simpler than wide-table but breaks
        cross-table relationships (foreign keys, joins).
      </p>
      <h3>MST (Marginal Synthesis)</h3>
      <p>
        Use the minimal sufficient statistics (MST) algorithm: identify low-cardinality marginals, estimate
        each under differential privacy, and reconstruct a synthetic table via Chow-Liu tree.
      </p>
      <p>
        Advantages: interpretable, works well for simple queries. Disadvantages: exponential in table width;
        fails on highly correlated attributes.
      </p>
    </section>

    <!-- EVALUATION FRAMEWORK -->
    <section class="section">
      <h2>Evaluation Framework</h2>
      <h3>Benchmark Queries</h3>
      <p>
        We executed 21 production-style SQL aggregate, ranking, and distribution queries across all methods.
      </p>
      <h3>Query Types</h3>
      <ul class="bullets">
        <li><strong>Aggregate:</strong> GROUP BY with SUM, COUNT, AVG (e.g., "power consumption by country")</li>
        <li><strong>Distribution:</strong> Histogram or category percentages (e.g., "browser usage %")</li>
        <li><strong>Ranking:</strong> Top-K items by some metric (e.g., "top 10 applications")</li>
        <li><strong>Row-level:</strong> Summary statistics on individual rows (e.g., row count, vendor distribution)</li>
      </ul>
      <h3>Metrics</h3>
      <ul class="bullets">
        <li><strong>Relative Error (RE):</strong> |synthetic - real| / |real|. Used for aggregate queries. Pass if median RE ≤ threshold (e.g., 0.3).</li>
        <li><strong>Total Variation (TV):</strong> 0.5 * sum |p_synth - p_real|. Used for distributions. Pass if TV ≤ threshold (e.g., 0.15).</li>
        <li><strong>Jaccard Similarity:</strong> |overlap| / |union| for group coverage. Pass if ≥ threshold (e.g., 0.5).</li>
        <li><strong>Spearman Rank Correlation:</strong> For ranking queries. Pass if rho ≥ threshold (e.g., 0.7).</li>
      </ul>
      <h3>Pass Criterion</h3>
      <p>
        A query passes if all relevant metrics pass their thresholds. A method's score is the number of queries passed.
      </p>
    </section>
  </main>

  <div id="siteFooter"></div>

  <script src="app.js"></script>
</body>
</html>
